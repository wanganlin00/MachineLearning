# 聚类

```{r}
library(tidymodels)
library(tidyclust)

```

```{r}
set.seed(10)
x_df <- tibble(
  V1 = rnorm(n = 50, mean = rep(c(0, 3), each = 25)),
  V2 = rnorm(n = 50, mean = rep(c(0, -4), each = 25))
)
```

```{r}
x_df %>%
  ggplot(aes(V1, V2, color = rep(c("A", "B"), each = 25))) +
  geom_point() +
  labs(color = "groups")
```

聚类分析的一般步骤

1.  选择合适的变量

2.  缩放数据 ：标准化

3.  寻找异常点

4.  计算距离： dist(x,method = ) 默认欧几里得距离

5.  选择聚类方法和算法

6.  确定类的数目

7.  获得最终的聚类解决方案

8.  结果可视化

9.  解读类

10. 验证结果

## 划分聚类 partitioning clustering

### K Means Cluster Specification

`num_clusters = 3`指定中心点（centroids）即类的个数，`nstart = 20`指定初始位置的个数，希望找到全局最大值而不是局部最大值

```{r}
kmeans_spec <-tidyclust::k_means(num_clusters = 3) %>%
  set_mode("partition") %>%
  set_engine("stats") %>%
  set_args(nstart = 20)

kmeans_spec


```

K-means algorithm starts with random initialization

```{r}
set.seed(100)
kmeans_fit <- kmeans_spec %>%
  fit(~., data = x_df)

kmeans_fit$fit

extract_centroids(kmeans_fit)
kmeans_fit$fit$centers

kmeans_fit$fit$cluster
```

```{r}
predict(kmeans_fit, new_data = x_df)
augment(kmeans_fit, new_data = x_df)
```

```{r}
augment(kmeans_fit, new_data = x_df) %>%
  ggplot(aes(V1, V2, color = .pred_cluster)) +
  geom_point()
```

`tune_cluster()`找到最适合的类的数目

```{r}
kmeans_spec_tuned <- kmeans_spec %>% 
  set_args(num_clusters = tune())

kmeans_wf <- workflow() %>%
  add_model(kmeans_spec_tuned) %>%
  add_formula(~.)
```

```{r}
set.seed(1000)
x_boots <- bootstraps(x_df, times = 10)

num_clusters_grid <- tibble(num_clusters = seq(1, 10))

tune_res <- tune_cluster(
  object = kmeans_wf,
  resamples = x_boots,
  grid = num_clusters_grid
)
```

```{r}
tune_res %>%
  collect_metrics()
```

[elbow method](https://en.wikipedia.org/wiki/Elbow_method_(clustering)) 找到最理想的类的个数。

```{r}
tune_res %>%
  autoplot()
```

调整后的聚类

```{r}
final_kmeans <- kmeans_wf %>%
  update_model(kmeans_spec %>% set_args(num_clusters = 2)) %>%
  fit(x_df)
```

```{r}
augment(final_kmeans, new_data = x_df) %>%
  ggplot(aes(V1, V2, color = .pred_cluster)) +
  geom_point()
```

## 分层聚类(小样本)Hierarchical Clustering

算法

1.  定义每个观测为一类

2.  计算每类与其他各类的距离

3.  把距离最短的两类合并成新的一类,总的类的个数减一

4.  重复2,3步骤,直到所有的类聚成单个类为止

### hclust specification

```{r}
res_hclust_complete <- tidyclust::hier_clust(linkage_method = "complete") %>%
  fit(~., data = x_df)

res_hclust_average <- hier_clust(linkage_method = "average") %>%
  fit(~., data = x_df)

res_hclust_single <- hier_clust(linkage_method = "single") %>%
  fit(~., data = x_df)
```

[*factoextra*](https://rpkgs.datanovia.com/factoextra/) package 提取模型信息和可视化

```{r}
library(factoextra)
res_hclust_complete %>%
  extract_fit_engine() %>%
  fviz_dend(main = "complete", k = 2)
```

```{r}
res_hclust_average %>%
  extract_fit_engine() %>%
  fviz_dend(main = "average", k = 2)
```

```{r}
res_hclust_single %>%
  extract_fit_engine() %>%
  fviz_dend(main = "single", k = 2)
```

```{r}
hier_rec <- recipe(~., data = x_df) %>%
  step_normalize(all_numeric_predictors()) # 标准化

hier_wf <- workflow() %>%
  add_recipe(hier_rec) %>%
  add_model(hier_clust(linkage_method = "complete"))

hier_fit <- hier_wf %>%
  fit(data = x_df) 

hier_fit %>%
  extract_fit_engine() %>%
  fviz_dend(k = 2)
```
