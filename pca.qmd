# 主成分分析

主成分分析(Principal component analysis，PCA) 是一种线性降维方法。

<https://bryanhanson.github.io/LearnPCA/articles//Vig_04_Scores_Loadings.html>

对于一组变量$X_1,X_2,...,X_p$,存在它们的线性组合 **Y**，令$Var(y_1)$最大，得到$y_1$，再找$y_2$，$y_2$与$y_1$正交，以此类推，找到一组无关主成分 **Y**。

$$
y_i=a_{i1}x_1+a_{i2}x_2+...+a_{ip}x_p\\
Cov(y_i,y_j)=
\begin{cases}  &\lambda_i,\ i=j \\  
& 0,\ i\ne j
\end{cases}
$$

## PCA自定义步骤

### 数据标准化

R中数据框 n个观测，p个变量， A~n×p~

$$
X=
\begin{bmatrix}
  x_{11}& x_{12} & ... & x_{1p}\\
 x_{21} & x_{22} & ... & x_{2p}\\
 \vdots  &  \vdots &   & \vdots \\
  x_{n1}& x_{n2} & ... & x_{np}
\end{bmatrix}
=(X_1,X_2,...X_p)
$$

对原始数据矩阵标准化，消除量纲和数量级的影响。

```{r}
df <- as_tibble(USArrests, rownames = "state") |> column_to_rownames("state")
head(df)

df_center <- scale(df,center = T,scale = T)
```

### 计算协方差矩阵

当$\Sigma$ 未知时，其用其估计值样本协方差矩阵S~p×p~ 代替

$$
S=\frac{AA^T}{n-1}
$$

-   $A_{ p×n}$ 显示来自每个变量值与变量平均值的距离$X_i-\bar X$；
-   \$(AA\^T)\_{ii} \$ 显示距离平方的总和(样本方差 $s_i^2$);
-   $(AA^T)_{ij}，i\ne j$ 显示样本协方差 $s_{ij} = (A 的行 i) · (A 的行 j)$。

```{r}
# 协方差矩阵公式
A <- as.matrix(t((df_center)))
AA_T <-A%*%t(A)
S <- AA_T/(50-1)
S
# 内置协方差矩阵函数
cov(df_center)
```

### 计算相关系数矩阵

R=（r~ij~）

$$
r_{ij}=\frac {S_{ij}}{\sqrt{S_{ii}×S_{jj}}}
$$

```{r}

r <- function(df){
    df <- as.data.frame(df)
    n=length(df)
    names <- colnames(df)
    df <- scale(df)
    S <- cov(df)
    r <- matrix(data = NA,n,n,dimnames = list(names,names))
    for(i in 1:n){
        for(j in 1:n){
            r[i,j]=S[i,j]/sqrt(S[i,i]*S[j,j])
        }
    }
    return(r)
}
r(df)
cor(df_center)
```

总方差T=所有特征值的总和=样本方差的总和=迹(对角线的总和)

`sum(eigen(AA_T)$values)`=`sum(diag(AA_T))`= `sum(svd$d^2)`

```{r}
# AA^T的特征值
y <- eigen(AA_T)
y$values
y$vectors

# 特征值的和
sum(y$values)

# 迹
sum(diag(AA_T))
```

### 奇异值分解

SVD公式：

$$
A_{p×n}=U\Sigma V^T 
$$

主成分推导：

$$ PC=VX=U \Sigma  $$

```{r}
svd <- svd(df_center)
svd$d
svd$u
svd$v
# 奇异值的平方和
sum(svd$d^2)

# 主成分荷载
svd$v



# 方差贡献百分比
pct <- svd$d^2/sum(svd$d^2)
pct



D <- diag(svd$d)

#  df_center  X = U D V'
X <- svd$u %*% D %*% t(svd$v) 

#  D = U' X V
t(svd$u) %*% X %*% svd$v


# 得分
svd$u %*% D
```

内置PCA

```{r}
pca <- prcomp(df_center)
pca

summary(pca)
library(ggfortify)
autoplot(prcomp(df_center),
         data=df_center,
         )
```

碎石图

```{r}
plot(svd$d,type="b")
plot(svd$d^2/sum(svd$d^2),type="b")
```

```{r}

svd$v
plot(svd$v[,1],ylab = "1st PC")
plot(svd$v[,2],ylab="2nd PC")
plot(svd$v[,3],ylab="3rd PC")
plot(svd$v[,4],ylab="4th PC")


plot(svd$v[,1],svd$v[,2],xlab="lst PC",ylab="2nd PC")

```

## 主成分分析

```{r}
library(tidymodels)
```

```{r}
df <- as_tibble(USArrests, rownames = "state")
head(df)

df |>
  select(-state) |>
  map_dfr(mean)  #apply(.,2,mean)
```

```{r}
df_pca <- df |>
  select(-state) |>
  stats::prcomp(scale = TRUE)

options(digits = 3)
df_pca
broom::tidy(df_pca, matrix = "scores")[1:6,] #by default    df_pca$x 长表
```

主成分荷载（loading）：表示主成分与原有变量的相关系数

```{r}
tidy(df_pca, matrix = "loadings")[1:6,]# df_pca$Rotation 长表
df_pca$rotation
```

例如：

$$
PC_1=-0.531Murrder-0.583Assault-0.278UrbanPop-0.543Rape
$$

```{r}

tidy(df_pca, matrix = "loadings") |>
  ggplot(aes(value, column)) +
  facet_wrap(~ PC) +
  geom_col() +
  scale_x_continuous(labels = scales::percent)
```

特征值 eigenvalues，高维椭球的主轴长度，相关矩阵的特征值。

方差百分比贡献。

```{r}
# screen plot
tidy(df_pca, matrix = "eigenvalues") |>
    ggplot(aes(PC, percent)) +
    geom_point(color = "red") +
    geom_line()+
    scale_y_continuous(labels = scales::percent)
```

### 判断主成分的个数`psych::fa.parallel(mat)`

1.  Cattell碎石图 图形变化最大处，即拐角处
2.  Kaiser-Harris准则 特征值大于1，直线y=1以上
3.  平行分析 基于真实数据的特征值大于一组随机数据矩阵相应的特征值（虚线）
