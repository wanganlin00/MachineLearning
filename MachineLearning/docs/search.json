[
  {
    "objectID": "tree.html",
    "href": "tree.html",
    "title": "",
    "section": "",
    "text": "有监督模型（Supervised Models）基于树的方法 CodeShow All CodeHide All CodeView Source",
    "crumbs": [
      "预测模型",
      "有监督模型（Supervised Models）",
      "基于树的方法"
    ]
  },
  {
    "objectID": "tree.html#决策树-分类",
    "href": "tree.html#决策树-分类",
    "title": "",
    "section": "\n1.1 决策树 （分类）",
    "text": "1.1 决策树 （分类）\n\nCodeclass_tree_spec &lt;- decision_tree() %&gt;%\n    set_engine(\"rpart\") %&gt;%\n    set_mode(\"classification\") \n\ndtree &lt;- class_tree_spec |&gt; fit(class ~ . ,data = train)\ndtree\n#&gt; parsnip model object\n#&gt; \n#&gt; n= 477 \n#&gt; \n#&gt; node), split, n, loss, yval, (yprob)\n#&gt;       * denotes terminal node\n#&gt; \n#&gt;  1) root 477 167 良性 (0.64989518 0.35010482)  \n#&gt;    2) 细胞大小均匀性&lt; 2.5 293  11 良性 (0.96245734 0.03754266)  \n#&gt;      4) 裸核&lt; 5.5 285   4 良性 (0.98596491 0.01403509) *\n#&gt;      5) 裸核&gt;=5.5 8   1 恶性 (0.12500000 0.87500000) *\n#&gt;    3) 细胞大小均匀性&gt;=2.5 184  28 恶性 (0.15217391 0.84782609)  \n#&gt;      6) 细胞形状均匀性&lt; 2.5 16   3 良性 (0.81250000 0.18750000) *\n#&gt;      7) 细胞形状均匀性&gt;=2.5 168  15 恶性 (0.08928571 0.91071429)  \n#&gt;       14) 细胞大小均匀性&lt; 4.5 46  12 恶性 (0.26086957 0.73913043)  \n#&gt;         28) 裸核&lt; 2.5 10   3 良性 (0.70000000 0.30000000) *\n#&gt;         29) 裸核&gt;=2.5 36   5 恶性 (0.13888889 0.86111111) *\n#&gt;       15) 细胞大小均匀性&gt;=4.5 122   3 恶性 (0.02459016 0.97540984) *\n\n\n模型摘要\n\nCodeplotcp(dtree$fit)\n\n\n\n\n\n\nCode\ndtree %&gt;%\n    extract_fit_engine() %&gt;%\n    rpart.plot(roundint = F)\n\n\n\n\n\n\n\n模型性能\n\nCodeaugment(dtree, new_data = test) %&gt;%\n    accuracy(truth = class, estimate = .pred_class)\n#&gt; # A tibble: 1 × 3\n#&gt;   .metric  .estimator .estimate\n#&gt;   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 accuracy binary         0.971\n\naugment(dtree, new_data = test) %&gt;%\n    conf_mat(truth = class, estimate = .pred_class)\n#&gt;           Truth\n#&gt; Prediction 良性 恶性\n#&gt;       良性  132    4\n#&gt;       恶性    2   68",
    "crumbs": [
      "预测模型",
      "有监督模型（Supervised Models）",
      "基于树的方法"
    ]
  },
  {
    "objectID": "tree.html#随机森林-分类",
    "href": "tree.html#随机森林-分类",
    "title": "",
    "section": "\n1.2 随机森林 （分类）",
    "text": "1.2 随机森林 （分类）\n\nCoderand_forest_randomForest_spec &lt;-\n    rand_forest(#mtry = .cols(), \n        trees = 500 ,min_n = 1) %&gt;%\n    set_engine('randomForest', importance = TRUE) %&gt;%\n    set_mode('classification')\n\nrf_fit &lt;- rand_forest_randomForest_spec |&gt; \n    fit(class ~ . , data = train)\nrf_fit\n#&gt; parsnip model object\n#&gt; \n#&gt; \n#&gt; Call:\n#&gt;  randomForest(x = maybe_data_frame(x), y = y, ntree = ~500, nodesize = min_rows(~1,      x), importance = ~TRUE) \n#&gt;                Type of random forest: classification\n#&gt;                      Number of trees: 500\n#&gt; No. of variables tried at each split: 3\n#&gt; \n#&gt;         OOB estimate of  error rate: 3.77%\n#&gt; Confusion matrix:\n#&gt;      良性 恶性 class.error\n#&gt; 良性  300   10  0.03225806\n#&gt; 恶性    8  159  0.04790419\n\n\nOOB out of bag 袋外预测误差，MeanDecreaseGini 基于Gini不纯度指数，用于衡量特征对数据集的不纯度减少的贡献。 值越大，表示特征对提高模型的纯度贡献越大，因此特征越重要。\n\nCoderf_fit$fit$importance\n#&gt;                         良性        恶性 MeanDecreaseAccuracy MeanDecreaseGini\n#&gt; 肿块厚度         0.045985557 0.041538273          0.044359259        12.465397\n#&gt; 细胞大小均匀性   0.049172066 0.076704399          0.058509661        47.927558\n#&gt; 细胞形状均匀性   0.009876762 0.096802558          0.040209397        41.331213\n#&gt; 边际附着力       0.016551632 0.035342949          0.023040888         6.945234\n#&gt; 单个上皮细胞大小 0.012280597 0.010654858          0.011723405        16.171318\n#&gt; 裸核             0.061713383 0.066225145          0.063075655        40.588065\n#&gt; bland_chromatin  0.017570370 0.058096398          0.031839179        31.183405\n#&gt; 正常核           0.027576658 0.021034748          0.025191390        17.830550\n#&gt; 有丝分裂         0.003095108 0.001130822          0.002400936         1.946241\n\n\n\nCode\naugment(rf_fit, new_data = test) %&gt;%\n    accuracy(truth = class, estimate = .pred_class)\n#&gt; # A tibble: 1 × 3\n#&gt;   .metric  .estimator .estimate\n#&gt;   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n#&gt; 1 accuracy binary         0.990\n\naugment(rf_fit, new_data = test) %&gt;%\n    conf_mat(truth = class, estimate = .pred_class)\n#&gt;           Truth\n#&gt; Prediction 良性 恶性\n#&gt;       良性  132    0\n#&gt;       恶性    2   72\n\n\n\n1.2.1 基于表达数据的应用\n\nCodedf &lt;- dendextend::khan\n\ndf$train.classes\n#&gt;  [1] EWS    EWS    EWS    EWS    EWS    EWS    EWS    EWS    EWS    EWS   \n#&gt; [11] EWS    EWS    EWS    EWS    EWS    EWS    EWS    EWS    EWS    EWS   \n#&gt; [21] EWS    EWS    EWS    BL-NHL BL-NHL BL-NHL BL-NHL BL-NHL BL-NHL BL-NHL\n#&gt; [31] BL-NHL NB     NB     NB     NB     NB     NB     NB     NB     NB    \n#&gt; [41] NB     NB     NB     RMS    RMS    RMS    RMS    RMS    RMS    RMS   \n#&gt; [51] RMS    RMS    RMS    RMS    RMS    RMS    RMS    RMS    RMS    RMS   \n#&gt; [61] RMS    RMS    RMS    RMS   \n#&gt; Levels: EWS BL-NHL NB RMS\ntrain &lt;- t(df$train) |&gt; bind_cols(tibble(class=df$train.classes)) |&gt; \n    relocate(class, .before = 1) |&gt; \n    mutate(\n        class=factor(class,levels = c(\"EWS\", \"BL-NHL\", \"NB\",\"RMS\"))\n    )\nstr(train$class)\n#&gt;  Factor w/ 4 levels \"EWS\",\"BL-NHL\",..: 1 1 1 1 1 1 1 1 1 1 ...\ntable(train$class)\n#&gt; \n#&gt;    EWS BL-NHL     NB    RMS \n#&gt;     23      8     12     21\n\n\n\nCodedf$test.classes\n#&gt;  [1] Normal Normal Normal NB     RMS    Normal Normal NB     EWS    RMS   \n#&gt; [11] BL-NHL EWS    RMS    EWS    EWS    EWS    RMS    BL-NHL RMS    NB    \n#&gt; [21] NB     NB     NB     BL-NHL EWS   \n#&gt; Levels: EWS BL-NHL NB RMS Normal\n\ntest &lt;- t(df$test) |&gt; bind_cols(tibble(class=df$test.classes)) |&gt; \n    relocate(class, .before = 1) |&gt; \n    mutate(\n        class=factor(class,levels = c(\"EWS\", \"BL-NHL\", \"NB\",\"RMS\",\"Normal\"))\n    )\nstr(test$class)\n#&gt;  Factor w/ 5 levels \"EWS\",\"BL-NHL\",..: 5 5 5 3 4 5 5 3 1 4 ...\ntable(test$class)\n#&gt; \n#&gt;    EWS BL-NHL     NB    RMS Normal \n#&gt;      6      3      6      5      5\n\n\n\nCode#\ndt &lt;- class_tree_spec |&gt; fit(class ~ . ,data = train)\nplotcp(dt$fit)\n\n\n\n\n\n\nCode\ndt%&gt;%\n    extract_fit_engine() %&gt;%\n    rpart.plot(roundint = F)\n\n\n\n\n\n\n\n\nCode#\nrf_fit &lt;- rand_forest_randomForest_spec |&gt; \n    fit(class ~ . , data = train)\nrf_fit\n#&gt; parsnip model object\n#&gt; \n#&gt; \n#&gt; Call:\n#&gt;  randomForest(x = maybe_data_frame(x), y = y, ntree = ~500, nodesize = min_rows(~1,      x), importance = ~TRUE) \n#&gt;                Type of random forest: classification\n#&gt;                      Number of trees: 500\n#&gt; No. of variables tried at each split: 17\n#&gt; \n#&gt;         OOB estimate of  error rate: 0%\n#&gt; Confusion matrix:\n#&gt;        EWS BL-NHL NB RMS class.error\n#&gt; EWS     23      0  0   0           0\n#&gt; BL-NHL   0      8  0   0           0\n#&gt; NB       0      0 12   0           0\n#&gt; RMS      0      0  0  21           0\n\nrf_fit$fit$importance\n#&gt;                   EWS        BL-NHL            NB           RMS\n#&gt; 25725    5.470058e-03  2.900000e-03  5.657143e-03  1.332410e-02\n#&gt; 193913   3.171645e-03  8.300000e-03  7.857143e-04  9.443001e-04\n#&gt; 725454   0.000000e+00  6.666667e-04  0.000000e+00  2.500000e-04\n#&gt; 297392  -2.777778e-05  2.000000e-03  1.000000e-04 -1.111111e-04\n#&gt; 236282   7.705628e-04  2.300000e-02  2.800000e-03  4.222222e-04\n#&gt; 298062   4.492063e-03  5.333333e-03  1.333333e-03  7.293651e-03\n#&gt; 284001  -2.500000e-04  2.000000e-03  0.000000e+00 -2.857143e-04\n#&gt; 283315  -8.571429e-05  4.666667e-03  4.000000e-04  4.666667e-04\n#&gt; 897177  -7.857143e-04  2.500000e-03  1.700000e-03  1.027778e-03\n#&gt; 755750  -1.190476e-04  4.200000e-03  1.833333e-03  2.857143e-03\n#&gt; 769716   4.073810e-03  1.100000e-02  1.310476e-02  1.727987e-02\n#&gt; 296448   6.290110e-03  1.020000e-02 -1.571429e-03  1.517729e-02\n#&gt; 435953   1.883256e-03  4.900000e-03  3.866667e-03  1.111111e-04\n#&gt; 343867   0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00\n#&gt; 365515   4.444444e-04  3.166667e-03  2.400000e-03  1.389899e-03\n#&gt; 769959   0.000000e+00  5.000000e-03  9.000000e-04  7.888889e-04\n#&gt; 491692  -3.636364e-04  0.000000e+00  3.333333e-04 -2.857143e-04\n#&gt; 756556   0.000000e+00  2.000000e-03  0.000000e+00 -7.857143e-04\n#&gt; 868304   4.444444e-04  2.000000e-03  1.166667e-03  0.000000e+00\n#&gt; 236034   0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00\n#&gt; 1469292  2.222222e-04  6.666667e-04  1.900000e-03  0.000000e+00\n#&gt; 767495   7.358586e-04  1.176667e-02  4.033333e-03  1.296508e-02\n#&gt; 377468   4.444444e-05  5.266667e-03 -1.904762e-05  3.822222e-03\n#&gt; 207274   7.699423e-03  8.000000e-03 -5.833333e-04  2.139632e-02\n#&gt; 796613   7.500000e-04  0.000000e+00  0.000000e+00  8.500000e-04\n#&gt; 1493527  0.000000e+00  6.666667e-04  0.000000e+00  0.000000e+00\n#&gt; 280507   4.444444e-04  1.466667e-03  2.500000e-04 -2.500000e-04\n#&gt; 461425   2.980586e-03  3.000000e-03  6.790476e-03  7.593651e-03\n#&gt; 163174   1.818182e-04  1.000000e-03  0.000000e+00  4.444444e-04\n#&gt; 68977    4.222222e-04  2.666667e-03  0.000000e+00  0.000000e+00\n#&gt; 769657  -2.500000e-04  2.000000e-03  6.666667e-04  0.000000e+00\n#&gt; 42558    1.777778e-04 -6.666667e-04  2.400000e-03  2.432540e-03\n#&gt; 44975   -1.142857e-04  1.000000e-04 -1.000000e-03  3.333333e-04\n#&gt; 45542    0.000000e+00  4.000000e-04  0.000000e+00  3.333333e-04\n#&gt; 301122  -3.818182e-04  0.000000e+00  2.500000e-04  1.571429e-03\n#&gt; 245330   1.666667e-04  0.000000e+00  9.000000e-04  8.222222e-04\n#&gt; 752652   0.000000e+00  0.000000e+00  9.714286e-04  2.500000e-04\n#&gt; 47475    0.000000e+00  4.100000e-03  0.000000e+00  2.857143e-04\n#&gt; 767183  -9.523810e-04  5.966667e-03  2.200000e-03 -5.151515e-04\n#&gt; 41591   -2.929293e-04  1.366667e-03  7.557143e-03  3.504329e-03\n#&gt; 241412   8.277778e-04  2.136667e-02  1.533333e-03  7.579365e-04\n#&gt; 183337  -4.944444e-04  1.090000e-02  3.866667e-03  3.636364e-04\n#&gt; 839552  -1.038961e-04  7.366667e-03  3.138095e-03  6.642208e-03\n#&gt; 789204   7.500000e-04  5.333333e-03  5.000000e-04 -3.818182e-04\n#&gt; 824602   2.222222e-04  1.333333e-03 -2.000000e-03  3.555556e-04\n#&gt; 796258   1.273061e-02 -2.000000e-04  1.250476e-02  3.183074e-02\n#&gt; 796904   0.000000e+00  1.333333e-03  0.000000e+00  2.222222e-04\n#&gt; 814465   0.000000e+00  5.233333e-03  0.000000e+00  0.000000e+00\n#&gt; 1409509  2.085714e-03  3.500000e-03  4.871429e-03  4.558730e-03\n#&gt; 489489   0.000000e+00  2.400000e-03  2.857143e-04  6.444444e-04\n#&gt; 263716   0.000000e+00  0.000000e+00  0.000000e+00  2.500000e-04\n#&gt; 755145  -3.571429e-05  5.666667e-03  6.666667e-04  1.865152e-03\n#&gt; 700792   0.000000e+00  9.000000e-04  0.000000e+00 -4.040404e-04\n#&gt; 788107   8.969697e-04  4.166667e-03  8.333333e-04  4.724892e-03\n#&gt; 843070   0.000000e+00  2.857143e-04  5.000000e-04  6.136364e-04\n#&gt; 246035   4.809474e-03  6.966667e-03  1.466667e-03  6.372944e-03\n#&gt; 66714    2.857143e-04  1.000000e-03  0.000000e+00  8.444444e-04\n#&gt; 143306   2.776862e-03  7.066667e-03  1.583333e-03  9.364574e-03\n#&gt; 324494   3.111111e-04  8.333333e-04  1.833333e-03  1.717460e-03\n#&gt; 490772   2.666667e-04  9.000000e-03  0.000000e+00  1.416667e-03\n#&gt; 770444  -2.500000e-04  4.500000e-03  9.000000e-04  2.857143e-04\n#&gt; 344134   2.857143e-04  5.333333e-03  0.000000e+00  7.301587e-04\n#&gt; 298417   0.000000e+00  8.000000e-04 -1.000000e-03  1.818182e-04\n#&gt; 855390   0.000000e+00  0.000000e+00  5.000000e-04  0.000000e+00\n#&gt; 770059   4.652015e-04  1.063333e-02  5.652381e-03  8.886508e-03\n#&gt; 80649    1.654762e-03  4.300000e-03  4.000000e-04  5.333333e-04\n#&gt; 745019   1.295455e-03  9.333333e-03  6.666667e-04 -2.500000e-04\n#&gt; 740604   2.000000e-04  5.000000e-03 -5.500000e-04  2.000000e-04\n#&gt; 781047   1.454545e-04  0.000000e+00  1.300000e-03  4.000000e-04\n#&gt; 129387   0.000000e+00  2.500000e-03  2.857143e-04  2.857143e-04\n#&gt; 773568  -3.333333e-04  6.666667e-04  0.000000e+00 -6.666667e-04\n#&gt; 530185   2.857143e-04  9.833333e-03  6.000000e-04  2.774747e-03\n#&gt; 810512  -2.000000e-04  0.000000e+00  0.000000e+00  0.000000e+00\n#&gt; 624360   1.285714e-03  8.800000e-03  5.000000e-04  1.750000e-03\n#&gt; 813841   3.248341e-03  5.466667e-03 -1.633333e-03  1.042582e-02\n#&gt; 813630   4.500000e-04 -1.666667e-04  3.333333e-04 -2.857143e-04\n#&gt; 200814   0.000000e+00  2.000000e-03  0.000000e+00  0.000000e+00\n#&gt; 813823   0.000000e+00  1.166667e-03 -1.666667e-04  0.000000e+00\n#&gt; 809901  -5.000000e-04  4.000000e-04  1.166667e-03  5.050505e-04\n#&gt; 122159   0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00\n#&gt; 298155   0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00\n#&gt; 714106   0.000000e+00  0.000000e+00  2.000000e-03  3.871429e-03\n#&gt; 609663   6.818182e-04  5.500000e-03  5.000000e-04  2.531258e-03\n#&gt; 789253   8.848485e-04  3.666667e-03  4.100000e-03  6.648701e-03\n#&gt; 898219   3.396970e-03  4.000000e-03 -7.000000e-04  9.120130e-03\n#&gt; 840942  -2.857143e-04  6.000000e-03  4.666667e-03  1.500000e-04\n#&gt; 80109    2.904040e-04  8.400000e-03  3.366667e-03  1.500000e-04\n#&gt; 782811  -2.222222e-04  6.333333e-03  2.857143e-04  1.729365e-03\n#&gt; 784224   7.117460e-03  6.666667e-05  1.408571e-02  2.917121e-02\n#&gt; 839736   0.000000e+00  1.000000e-03  0.000000e+00  9.000000e-04\n#&gt; 151261   1.166667e-03  1.400000e-03  2.800000e-03  5.079365e-04\n#&gt; 244618   3.475397e-03  5.733333e-03  7.904762e-04  9.281962e-03\n#&gt; 111884   6.944444e-04  1.333333e-03  1.685714e-03  3.407937e-03\n#&gt; 139705   3.333333e-04  3.000000e-03  5.000000e-04  3.333333e-04\n#&gt; 262920   2.000000e-04  4.000000e-04 -1.000000e-04  1.333333e-04\n#&gt; 293500   5.713564e-03  7.566667e-03 -1.833333e-03  1.030000e-02\n#&gt; 142134  -2.277778e-04  3.333333e-03  6.671429e-03  3.977778e-03\n#&gt; 380620   2.966667e-03  4.233333e-03 -1.900000e-03  2.284343e-03\n#&gt; 417226   3.333333e-04  1.500000e-03  5.000000e-04  3.666667e-04\n#&gt; 1048810 -3.076923e-04  5.500000e-03  5.000000e-04  5.714286e-04\n#&gt; 39796    1.416667e-03 -1.333333e-03  3.666667e-03  2.000000e-04\n#&gt; 39093    0.000000e+00  6.666667e-04  4.000000e-04  2.000000e-04\n#&gt; 137158   0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00\n#&gt; 365826   1.762843e-03  1.896667e-02  1.137619e-02  7.900744e-03\n#&gt; 377731   2.194444e-03  2.500000e-03  9.000000e-04 -8.571429e-05\n#&gt; 345553   4.166667e-04  0.000000e+00  8.000000e-04  2.222222e-04\n#&gt; 486175   7.500000e-04  0.000000e+00  1.666667e-03  0.000000e+00\n#&gt; 729964  -2.500000e-04  1.000000e-03 -6.666667e-04  2.222222e-04\n#&gt; 362483   3.571429e-05 -4.000000e-04  6.857143e-04  7.500000e-04\n#&gt; 383188   1.406566e-03  5.666667e-03  7.938095e-03  2.222222e-04\n#&gt; 345232   7.365873e-03  4.900000e-03  2.171429e-03  9.603175e-04\n#&gt; 307660   4.444444e-04  5.000000e-04  0.000000e+00 -2.500000e-04\n#&gt; 68950    4.714358e-03  1.733333e-03  1.869048e-03  2.072222e-03\n#&gt; 744417  -2.000000e-04  3.366667e-03 -6.666667e-04  0.000000e+00\n#&gt; 377461   3.111602e-02  8.652381e-03  2.125238e-02  7.654706e-03\n#&gt; 486787   1.571429e-03  2.400000e-03  2.050000e-03 -2.857143e-04\n#&gt; 325182   3.492951e-03  2.500000e-03  1.636190e-02  1.455556e-03\n#&gt; 740801   0.000000e+00  1.333333e-03  1.666667e-04  0.000000e+00\n#&gt; 197657   0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00\n#&gt; 1470048  1.035714e-03 -6.666667e-04  2.500000e-03  2.500000e-04\n#&gt; 1323448  7.222222e-04 -2.500000e-03  1.733333e-03  7.579365e-04\n#&gt; 1456900  0.000000e+00  0.000000e+00  5.333333e-04  0.000000e+00\n#&gt; 1434905 -2.000000e-04  5.000000e-04  9.523810e-04 -7.222222e-04\n#&gt; 1473131  1.056593e-02  8.500000e-03  3.566667e-03  3.170707e-03\n#&gt; 291756   4.690476e-04  5.000000e-04 -5.000000e-04  1.316667e-03\n#&gt; 431397   1.321429e-03  0.000000e+00  5.714286e-04  7.333333e-04\n#&gt; 195751   0.000000e+00  6.666667e-04  5.000000e-04  0.000000e+00\n#&gt; 172751   3.333333e-04  0.000000e+00  0.000000e+00 -2.500000e-04\n#&gt; 379708   1.850000e-03  4.800000e-03  2.966667e-03  6.871795e-04\n#&gt; 448386   6.651010e-03 -1.857143e-03  1.100000e-02  6.597403e-04\n#&gt; 878798   2.500000e-04  0.000000e+00  0.000000e+00  0.000000e+00\n#&gt; 768644   0.000000e+00  5.200000e-03  6.857143e-04  0.000000e+00\n#&gt; 32493    2.857143e-04  0.000000e+00  0.000000e+00  0.000000e+00\n#&gt; 1412412  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00\n#&gt; 1435862  4.293167e-02  2.386667e-02  1.722381e-02  7.290693e-03\n#&gt; 357031   1.350596e-02  8.233333e-03  4.204762e-03  2.150072e-03\n#&gt; 810504   4.000000e-04  0.000000e+00  0.000000e+00  5.000000e-04\n#&gt; 811108   5.471429e-03  5.000000e-03  2.633333e-03  5.666667e-04\n#&gt; 178463   0.000000e+00  2.000000e-03  0.000000e+00  0.000000e+00\n#&gt; 812196   6.666667e-04  6.666667e-04  1.333333e-03  2.000000e-04\n#&gt; 811920   8.333333e-04  0.000000e+00  0.000000e+00 -1.818182e-04\n#&gt; 753587  -2.857143e-04  0.000000e+00  0.000000e+00  0.000000e+00\n#&gt; 812105   5.357143e-04  3.833333e-03  2.086667e-02  1.441270e-03\n#&gt; 144932   6.666667e-04  5.000000e-03  1.316667e-03  5.000000e-05\n#&gt; 212640  -5.000000e-04  0.000000e+00  3.466667e-03 -1.714286e-04\n#&gt; 770868   4.127778e-03  6.666667e-03  5.833333e-04 -3.333333e-05\n#&gt; 134748   2.554928e-03  2.133333e-03  1.619048e-02 -8.944444e-04\n#&gt; 768443  -1.818182e-04  0.000000e+00 -6.000000e-04  1.666667e-04\n#&gt; 563673   1.349351e-03  3.016667e-02  2.383333e-03  5.833333e-04\n#&gt; 784593   4.527850e-03  2.250000e-02  9.919048e-03  1.017460e-03\n#&gt; 789091  -2.857143e-04  6.666667e-04  6.666667e-04 -6.666667e-04\n#&gt; 786084   3.854257e-03  4.952381e-03  1.327619e-02 -1.550000e-03\n#&gt; 815239   2.857143e-04  3.000000e-03  3.119048e-03 -2.976190e-04\n#&gt; 898218   2.000000e-04  1.066667e-03  6.666667e-05  0.000000e+00\n#&gt; 767345   2.222222e-04  0.000000e+00  0.000000e+00  0.000000e+00\n#&gt; 1475730  3.333333e-04  0.000000e+00  0.000000e+00  2.500000e-04\n#&gt; 1471841  1.096537e-02  5.633333e-03  2.266667e-03  3.002525e-03\n#&gt; 812965   2.357143e-03 -6.666667e-04  1.000000e-03  4.444444e-04\n#&gt; 75254    2.664835e-03  1.133333e-03  2.171429e-03  3.333333e-04\n#&gt; 760224   0.000000e+00  0.000000e+00 -4.000000e-04 -2.857143e-04\n#&gt; 207358   1.525613e-03 -2.333333e-03  2.438095e-03 -4.372294e-04\n#&gt; 859359   5.833550e-03  1.583333e-02  3.500000e-03  7.669048e-03\n#&gt; 137535   1.636364e-04  1.166667e-03  2.857143e-04 -1.666667e-04\n#&gt; 52096    0.000000e+00  1.400000e-03 -2.857143e-04  0.000000e+00\n#&gt; 809694   2.857143e-04  6.666667e-04 -5.000000e-04  0.000000e+00\n#&gt; 298231   0.000000e+00  0.000000e+00  0.000000e+00  6.666667e-04\n#&gt; 755599   7.579365e-04  0.000000e+00  4.100000e-03 -3.888889e-05\n#&gt; 742132   1.818182e-04  0.000000e+00  1.800000e-03  0.000000e+00\n#&gt; 382564   0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00\n#&gt; 866702   9.590693e-03  6.333333e-03  1.666667e-03  3.589683e-03\n#&gt; 491565   6.158802e-03  7.933333e-03  1.666667e-03  1.890332e-04\n#&gt; 178825   2.044444e-03 -1.400000e-03  4.000000e-04  3.333333e-04\n#&gt; 882506   5.357143e-04  0.000000e+00 -5.714286e-04  0.000000e+00\n#&gt; 743229   8.571429e-04  6.666667e-04  1.485714e-03  0.000000e+00\n#&gt; 770394   3.899718e-02  1.656667e-02  1.885714e-02  1.341419e-02\n#&gt; 198982   0.000000e+00  0.000000e+00  0.000000e+00  4.000000e-04\n#&gt; 586854   2.141126e-03  5.000000e-03  1.166667e-03  0.000000e+00\n#&gt; 505491   9.047619e-04  4.000000e-04  1.300000e-03  1.587302e-04\n#&gt; 470261   2.222222e-04  0.000000e+00  0.000000e+00  2.857143e-04\n#&gt; 364934   1.892063e-03  4.800000e-03  2.857143e-04  1.158730e-03\n#&gt; 82225    0.000000e+00  6.666667e-04  2.857143e-04  0.000000e+00\n#&gt; 629896   7.152015e-04  3.200000e-03  5.071429e-03  1.394444e-03\n#&gt; 80338    4.942857e-03  1.206667e-02  1.250000e-03  1.333333e-03\n#&gt; 811000   1.151515e-04  3.000000e-03 -8.333333e-04  7.500000e-04\n#&gt; 52076    1.147337e-02  6.833333e-03  7.000000e-04  1.167727e-02\n#&gt; 377048   4.381624e-03  5.000000e-03  1.430000e-02 -7.357143e-04\n#&gt; 1031748  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00\n#&gt; 785967  -1.200000e-03  1.466667e-03  1.400000e-03  0.000000e+00\n#&gt; 813698   1.931818e-03  2.000000e-03 -4.000000e-04  3.583333e-03\n#&gt; 43733    1.100794e-02  2.283333e-02  5.747619e-03  2.661111e-03\n#&gt; 53039   -2.500000e-04  0.000000e+00  0.000000e+00  0.000000e+00\n#&gt; 754600   0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00\n#&gt; 361943   7.777778e-04  3.333333e-03  0.000000e+00 -6.190476e-04\n#&gt; 44563    1.166667e-03  6.166667e-03  7.350000e-03  1.944444e-04\n#&gt; 713922   8.094084e-03  1.333333e-02  6.952381e-03  8.523810e-04\n#&gt; 768246   0.000000e+00  0.000000e+00  3.333333e-04  6.666667e-04\n#&gt; 753104  -4.444444e-05  0.000000e+00  5.000000e-04  0.000000e+00\n#&gt; 214572   9.090476e-03 -1.366667e-03 -7.333333e-04  2.804762e-03\n#&gt; 124605   4.000000e-04  4.166667e-03  9.000000e-04  1.507937e-03\n#&gt; 755506   2.500000e-04  0.000000e+00  3.333333e-04 -1.666667e-04\n#&gt; 208718   7.428571e-04  1.600000e-03  0.000000e+00  8.857143e-04\n#&gt; 51448    0.000000e+00  2.400000e-03  1.000000e-03  2.857143e-04\n#&gt; 773215   7.299145e-04  6.666667e-04  0.000000e+00  2.222222e-04\n#&gt; 774502   5.799634e-03  7.700000e-03  9.333333e-03  4.095238e-04\n#&gt; 714453   1.782540e-03  1.600000e-03  4.300000e-03  3.248485e-03\n#&gt; 814260   3.369048e-02  2.053333e-02  2.013810e-02  1.267973e-02\n#&gt; 71672    2.000000e-04  0.000000e+00  1.400000e-03  0.000000e+00\n#&gt; 841641   5.197613e-03  1.583333e-02  1.283333e-03  1.830952e-03\n#&gt; 740554   1.400000e-03  0.000000e+00  2.857143e-04  2.222222e-04\n#&gt; 295985   2.949206e-02  1.766667e-02  1.280000e-02  1.064901e-02\n#&gt; 234376   0.000000e+00  0.000000e+00  3.333333e-04  0.000000e+00\n#&gt; 138672   3.333333e-04 -8.000000e-04  0.000000e+00  3.571429e-05\n#&gt; 139957   9.615385e-04 -5.000000e-04 -2.142857e-04 -3.333333e-04\n#&gt; 308231   3.380952e-03  5.000000e-03  9.100000e-03 -2.000000e-04\n#&gt; 309864   0.000000e+00  5.000000e-04  0.000000e+00  2.500000e-04\n#&gt; 341588   1.900000e-03  0.000000e+00  6.666667e-04  1.583333e-03\n#&gt; 308497   2.801587e-03  6.866667e-03  5.585714e-03 -3.388889e-04\n#&gt; 269354   5.673882e-04  6.666667e-04 -4.000000e-04  1.944444e-04\n#&gt; 376802   0.000000e+00  0.000000e+00  0.000000e+00 -2.500000e-04\n#&gt; 811028   0.000000e+00  5.000000e-04  0.000000e+00  0.000000e+00\n#&gt; 810133   8.571429e-04  0.000000e+00  0.000000e+00  0.000000e+00\n#&gt; 810448   0.000000e+00  0.000000e+00 -2.857143e-04 -4.000000e-04\n#&gt; 364510   0.000000e+00  0.000000e+00  0.000000e+00 -2.222222e-04\n#&gt; 745343   0.000000e+00  2.000000e-03  5.433333e-03  4.722222e-04\n#&gt; 431296   0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00\n#&gt; 145112  -2.500000e-04  2.000000e-03 -5.000000e-04  4.000000e-04\n#&gt; 878280  -4.500000e-04  9.500000e-03  4.135714e-03  1.016067e-03\n#&gt; 505881   1.070707e-03  6.433333e-03 -2.666667e-04 -2.777778e-05\n#&gt; 289645   7.301587e-04  2.133333e-03  1.333333e-03  2.380952e-03\n#&gt; 395708   7.857143e-04  2.400000e-03  2.000000e-03  0.000000e+00\n#&gt; 756401   5.000000e-04  3.666667e-04  8.119048e-03  2.427778e-03\n#&gt; 450152  -3.333333e-04  2.400000e-03  2.166667e-03  2.222222e-04\n#&gt; 815794   0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00\n#&gt; 825740   0.000000e+00  6.666667e-04 -5.000000e-04 -3.333333e-04\n#&gt; 823886   3.636364e-04  6.233333e-03  2.500000e-03  1.818182e-04\n#&gt; 207082   0.000000e+00  8.000000e-04  2.000000e-03  0.000000e+00\n#&gt; 376516   0.000000e+00 -1.000000e-03  3.052381e-03  2.119048e-03\n#&gt; 813707   0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00\n#&gt; 213136   1.818182e-04  0.000000e+00  0.000000e+00  0.000000e+00\n#&gt; 823901   0.000000e+00  1.000000e-03  0.000000e+00  0.000000e+00\n#&gt; 234237  -2.500000e-04  4.666667e-03  1.333333e-03  0.000000e+00\n#&gt; 549146   4.761905e-04  0.000000e+00  1.500000e-04  2.500000e-04\n#&gt; 306901   1.666667e-04  0.000000e+00  0.000000e+00 -4.000000e-04\n#&gt; 810057   6.801587e-04 -5.000000e-04  1.663333e-02  2.907570e-03\n#&gt; 841340   0.000000e+00  1.000000e-03  1.500000e-03 -2.500000e-04\n#&gt; 81518   -1.262626e-04  7.166667e-03  1.690476e-02  1.516667e-03\n#&gt; 813266   8.571429e-05  4.000000e-03  5.000000e-04 -5.833333e-04\n#&gt; 785933   2.000000e-04  0.000000e+00  0.000000e+00  0.000000e+00\n#&gt; 416959   5.714286e-04  3.166667e-03  1.000000e-03  1.935065e-03\n#&gt; 52079    0.000000e+00  0.000000e+00 -6.000000e-04  0.000000e+00\n#&gt; 841620   3.199206e-03  1.080000e-02  2.352381e-03  1.695527e-03\n#&gt; 726236   2.857143e-04  4.000000e-04  5.000000e-04 -4.318182e-04\n#&gt; 949934   2.857143e-04  5.000000e-04  8.000000e-04  4.365079e-04\n#&gt; 760299  -2.222222e-04  2.000000e-03  1.833333e-03  0.000000e+00\n#&gt; 486110   3.571429e-04  4.500000e-03  6.633333e-03 -5.111111e-04\n#&gt; 1474174 -2.857143e-04  5.900000e-03  1.650000e-03 -3.214286e-04\n#&gt; 878652   1.045455e-03  7.166667e-03  1.160000e-02 -7.905983e-04\n#&gt; 85171   -3.000000e-04  1.900000e-03  5.785714e-03  8.190476e-04\n#&gt; 753418   6.825397e-04  1.833333e-03  4.552381e-03  5.000000e-04\n#&gt; 626502   3.333333e-04  7.866667e-03  1.952381e-03  6.190476e-04\n#&gt; 814526   0.000000e+00  6.000000e-03  9.000000e-04 -1.285714e-04\n#&gt; 299630   3.636364e-04  9.000000e-04 -1.333333e-03  0.000000e+00\n#&gt; 502333   0.000000e+00  6.000000e-03  8.888889e-04  2.000000e-04\n#&gt; 435551   0.000000e+00  0.000000e+00 -5.000000e-04 -2.857143e-04\n#&gt; 470128   0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00\n#&gt; 866694   0.000000e+00 -1.000000e-03  3.000000e-03 -6.837607e-05\n#&gt; 32299   -1.818182e-04  8.000000e-04  4.166667e-03  4.277778e-04\n#&gt; 504791   1.130159e-03  1.633333e-02  6.190476e-04  2.500000e-04\n#&gt; 784257   5.079365e-04  6.800000e-03  2.685714e-03  9.461039e-04\n#&gt; 755228  -2.857143e-04  8.000000e-04  1.000000e-03 -1.666667e-04\n#&gt; 292996   4.444444e-04  0.000000e+00  0.000000e+00  4.000000e-04\n#&gt; 770014   1.666667e-04  4.666667e-04  1.400000e-03  5.714286e-04\n#&gt; 842918   1.865079e-03  8.666667e-03  2.607143e-03 -7.222222e-04\n#&gt; 626555   0.000000e+00  0.000000e+00 -5.000000e-04  0.000000e+00\n#&gt; 877664   1.166667e-03  6.500000e-03  2.452381e-03 -4.722222e-04\n#&gt; 843098   0.000000e+00  0.000000e+00  0.000000e+00  5.000000e-04\n#&gt; 811956   0.000000e+00  0.000000e+00  0.000000e+00 -1.666667e-04\n#&gt; 244307   0.000000e+00  0.000000e+00  0.000000e+00 -2.857143e-04\n#&gt; 140806   0.000000e+00  6.666667e-04  5.000000e-04  0.000000e+00\n#&gt; 753215   0.000000e+00  1.333333e-03  1.066667e-03 -3.333333e-04\n#&gt; 220096  -1.818182e-05  0.000000e+00  1.257143e-03  1.111111e-04\n#&gt; 789376  -3.750000e-04  3.333333e-04  4.852381e-03  1.465201e-03\n#&gt; 79520    1.818182e-04  2.000000e-03  1.833333e-03  3.333333e-04\n#&gt; 361974   0.000000e+00  5.600000e-03 -1.666667e-04  0.000000e+00\n#&gt; 789357   2.222222e-04  3.800000e-03  2.666667e-04 -2.500000e-04\n#&gt; 824704   2.655303e-03  1.500000e-03  6.750000e-03 -1.000000e-03\n#&gt; 843287   0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00\n#&gt; 85259    0.000000e+00  0.000000e+00  8.333333e-04  3.333333e-04\n#&gt; 701751  -4.000000e-04  4.000000e-03  2.857143e-04 -4.000000e-04\n#&gt; 280837   2.597403e-06  4.066667e-03  3.309524e-03  1.600649e-03\n#&gt; 108351   3.492063e-04  6.733333e-03  8.333333e-04  2.000000e-04\n#&gt; 134495   0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00\n#&gt; 135058   0.000000e+00  1.000000e-03  6.857143e-04  3.333333e-04\n#&gt; 205490   0.000000e+00  8.000000e-04  5.000000e-04  2.857143e-04\n#&gt; 292522   0.000000e+00 -6.666667e-04 -5.000000e-04  2.222222e-04\n#&gt; 193182   2.857143e-04  4.000000e-03  2.857143e-03  0.000000e+00\n#&gt; 244637   1.666667e-04  1.666667e-04  8.290476e-03  5.252747e-04\n#&gt; 130892   0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00\n#&gt; 240208  -4.000000e-04  1.066667e-03  2.500000e-03 -1.538462e-04\n#&gt; 135688   1.481818e-03  3.400000e-03  3.000000e-03  5.357143e-04\n#&gt; 110503   2.222222e-04  1.000000e-03  0.000000e+00  0.000000e+00\n#&gt; 413633   3.555556e-04  0.000000e+00  0.000000e+00  1.200000e-03\n#&gt; 783697   0.000000e+00  0.000000e+00  0.000000e+00  5.333333e-04\n#&gt; 247582   0.000000e+00  2.000000e-03  5.000000e-04  0.000000e+00\n#&gt; 323917   6.666667e-04  0.000000e+00 -3.333333e-04  0.000000e+00\n#&gt; 782503   1.015873e-03  4.300000e-03  1.650000e-03  3.030303e-05\n#&gt;         MeanDecreaseAccuracy MeanDecreaseGini\n#&gt; 25725           7.719801e-03      0.618040321\n#&gt; 193913          2.674676e-03      0.175751667\n#&gt; 725454          1.666667e-04      0.017181485\n#&gt; 297392          2.269565e-04      0.046364777\n#&gt; 236282          3.293713e-03      0.346336193\n#&gt; 298062          5.148307e-03      0.420162692\n#&gt; 284001          8.571429e-05      0.045811987\n#&gt; 283315          7.306563e-04      0.072926493\n#&gt; 897177          7.399134e-04      0.096557738\n#&gt; 755750          1.691908e-03      0.129916225\n#&gt; 769716          1.100367e-02      0.692583775\n#&gt; 296448          7.730713e-03      0.593274596\n#&gt; 435953          2.162144e-03      0.164338662\n#&gt; 343867          0.000000e+00      0.002000000\n#&gt; 365515          1.630000e-03      0.102225228\n#&gt; 769959          1.108968e-03      0.138398223\n#&gt; 491692         -1.538462e-04      0.037883333\n#&gt; 756556          7.051282e-05      0.029695573\n#&gt; 868304          5.422222e-04      0.041875626\n#&gt; 236034          0.000000e+00      0.024048583\n#&gt; 1469292         5.523445e-04      0.045819964\n#&gt; 767495          6.234928e-03      0.496901138\n#&gt; 377468          1.949731e-03      0.159785871\n#&gt; 207274          1.090822e-02      0.730954681\n#&gt; 796613          5.852632e-04      0.022139627\n#&gt; 1493527         8.333333e-05      0.008000000\n#&gt; 280507          3.881988e-04      0.041191087\n#&gt; 461425          5.207371e-03      0.411322678\n#&gt; 163174          4.430171e-04      0.030434286\n#&gt; 68977           4.083851e-04      0.080657429\n#&gt; 769657          1.861472e-04      0.067647192\n#&gt; 42558           1.264129e-03      0.156328027\n#&gt; 44975          -9.259259e-05      0.074204022\n#&gt; 45542           1.800000e-04      0.010933333\n#&gt; 301122          4.038721e-04      0.037722944\n#&gt; 245330          6.117216e-04      0.045072692\n#&gt; 752652          3.504762e-04      0.023434524\n#&gt; 47475           8.636156e-04      0.048295238\n#&gt; 767183          8.207692e-04      0.095939025\n#&gt; 41591           2.597739e-03      0.166455334\n#&gt; 241412          3.345021e-03      0.234584684\n#&gt; 183337          1.978210e-03      0.144047078\n#&gt; 839552          3.768938e-03      0.348444705\n#&gt; 789204          5.772129e-04      0.115588630\n#&gt; 824602          1.733333e-04      0.045509795\n#&gt; 796258          1.617029e-02      1.090589485\n#&gt; 796904          2.364469e-04      0.060792061\n#&gt; 814465          7.416388e-04      0.032466523\n#&gt; 1409509         3.108706e-03      0.256296433\n#&gt; 489489          4.988278e-04      0.068427960\n#&gt; 263716          1.000000e-04      0.014729323\n#&gt; 755145          1.474096e-03      0.089624311\n#&gt; 700792          3.952569e-06      0.019898405\n#&gt; 788107          2.390379e-03      0.191704298\n#&gt; 843070          3.974603e-04      0.024038534\n#&gt; 246035          4.643325e-03      0.464670085\n#&gt; 66714           4.961353e-04      0.034405476\n#&gt; 143306          5.330241e-03      0.454492853\n#&gt; 324494          1.072628e-03      0.109741920\n#&gt; 490772          1.625185e-03      0.186503484\n#&gt; 770444          1.044356e-03      0.071791831\n#&gt; 344134          1.007626e-03      0.084968717\n#&gt; 298417          6.769231e-05      0.027077778\n#&gt; 855390          9.090909e-05      0.017076923\n#&gt; 770059          5.272268e-03      0.343725914\n#&gt; 80649           1.642502e-03      0.070734929\n#&gt; 745019          1.480943e-03      0.133868304\n#&gt; 740604          5.869115e-04      0.161129039\n#&gt; 781047          5.008696e-04      0.065487217\n#&gt; 129387          5.141026e-04      0.045598869\n#&gt; 773568         -2.766798e-04      0.069857884\n#&gt; 530185          2.482128e-03      0.192439373\n#&gt; 810512         -7.692308e-05      0.019824561\n#&gt; 624360          1.906049e-03      0.123503841\n#&gt; 813841          4.944915e-03      0.405540172\n#&gt; 813630          1.749482e-04      0.060793297\n#&gt; 200814          1.861472e-04      0.044268519\n#&gt; 813823          1.481481e-04      0.032450980\n#&gt; 809901          2.089485e-04      0.102172347\n#&gt; 122159          0.000000e+00      0.000000000\n#&gt; 298155          0.000000e+00      0.000000000\n#&gt; 714106          1.430833e-03      0.049675101\n#&gt; 609663          1.821502e-03      0.154478727\n#&gt; 789253          3.774685e-03      0.271559872\n#&gt; 898219          4.707837e-03      0.413172772\n#&gt; 840942          1.218560e-03      0.129041054\n#&gt; 80109           1.485119e-03      0.129968557\n#&gt; 782811          1.288357e-03      0.134424943\n#&gt; 784224          1.481415e-02      1.097002417\n#&gt; 839736          4.110276e-04      0.027150058\n#&gt; 151261          1.242844e-03      0.072811244\n#&gt; 244618          5.344022e-03      0.420775833\n#&gt; 111884          1.934719e-03      0.177485735\n#&gt; 139705          7.429293e-04      0.064698046\n#&gt; 262920          1.914539e-04      0.049252887\n#&gt; 293500          5.791144e-03      0.431781515\n#&gt; 142134          2.716733e-03      0.275151810\n#&gt; 380620          1.912455e-03      0.159584101\n#&gt; 417226          5.194805e-04      0.078366255\n#&gt; 1048810         5.894540e-04      0.060839419\n#&gt; 39796           1.249417e-03      0.097227309\n#&gt; 39093           3.596838e-04      0.014720000\n#&gt; 137158          0.000000e+00      0.002000000\n#&gt; 365826          7.687991e-03      0.499647262\n#&gt; 377731          1.255664e-03      0.096602076\n#&gt; 345553          4.239130e-04      0.011206349\n#&gt; 486175          4.883450e-04      0.023772762\n#&gt; 729964          2.608696e-05      0.036310345\n#&gt; 362483          2.536232e-04      0.049314468\n#&gt; 383188          3.199524e-03      0.231896577\n#&gt; 345232          3.949382e-03      0.204793940\n#&gt; 307660          1.666667e-04      0.014450526\n#&gt; 68950           2.764752e-03      0.355275956\n#&gt; 744417          3.013131e-04      0.062721489\n#&gt; 377461          1.789016e-02      1.212184730\n#&gt; 486787          1.209078e-03      0.056914166\n#&gt; 325182          4.910433e-03      0.365265975\n#&gt; 740801          1.669565e-04      0.021274725\n#&gt; 197657          0.000000e+00      0.004666667\n#&gt; 1470048         5.745307e-04      0.107874473\n#&gt; 1323448         5.926877e-04      0.103253083\n#&gt; 1456900         1.947368e-04      0.051140886\n#&gt; 1434905         6.906390e-05      0.104905285\n#&gt; 1473131         6.451299e-03      0.423058212\n#&gt; 291756          6.616162e-04      0.074988266\n#&gt; 431397          8.000000e-04      0.018328420\n#&gt; 195751          1.739130e-04      0.007000000\n#&gt; 172751          7.575758e-06      0.035050794\n#&gt; 379708          2.029612e-03      0.173895956\n#&gt; 448386          3.679384e-03      0.295551955\n#&gt; 878798          8.695652e-05      0.010173913\n#&gt; 768644          8.177778e-04      0.050987879\n#&gt; 32493           8.333333e-05      0.007384615\n#&gt; 1412412         0.000000e+00      0.000000000\n#&gt; 1435862         2.352097e-02      1.544397266\n#&gt; 357031          7.240701e-03      0.464970158\n#&gt; 810504          2.774327e-04      0.011484876\n#&gt; 811108          3.119408e-03      0.216368365\n#&gt; 178463          2.105263e-04      0.010177778\n#&gt; 812196          6.026936e-04      0.043757514\n#&gt; 811920          3.809524e-04      0.037739224\n#&gt; 753587         -8.333333e-05      0.003800000\n#&gt; 812105          4.245107e-03      0.370042198\n#&gt; 144932          9.120083e-04      0.099010406\n#&gt; 212640          5.212121e-04      0.058920508\n#&gt; 770868          2.306257e-03      0.276682527\n#&gt; 134748          4.235292e-03      0.345993482\n#&gt; 768443          0.000000e+00      0.017038695\n#&gt; 563673          3.496139e-03      0.388788021\n#&gt; 784593          6.515580e-03      0.483269610\n#&gt; 789091         -4.858300e-05      0.037670032\n#&gt; 786084          3.365256e-03      0.339929082\n#&gt; 815239          9.547379e-04      0.084449411\n#&gt; 898218          2.608696e-04      0.034252381\n#&gt; 767345          8.333333e-05      0.011448276\n#&gt; 1475730         1.904762e-04      0.008506667\n#&gt; 1471841         6.029246e-03      0.488402967\n#&gt; 812965          8.211640e-04      0.049501997\n#&gt; 75254           1.850759e-03      0.126520708\n#&gt; 760224         -1.610306e-04      0.024236364\n#&gt; 207358          9.580957e-04      0.177480048\n#&gt; 859359          6.431337e-03      0.397220106\n#&gt; 137535          3.329555e-04      0.055900362\n#&gt; 52096           1.448876e-04      0.024828238\n#&gt; 809694          1.556064e-04      0.035953156\n#&gt; 298231          1.818182e-04      0.003833333\n#&gt; 755599          1.090055e-03      0.126651202\n#&gt; 742132          4.794372e-04      0.032211400\n#&gt; 382564          0.000000e+00      0.003500000\n#&gt; 866702          5.781756e-03      0.540372450\n#&gt; 491565          3.562454e-03      0.288088475\n#&gt; 178825          4.570745e-04      0.073139426\n#&gt; 882506          5.238095e-05      0.047380144\n#&gt; 743229          7.481685e-04      0.057818365\n#&gt; 770394          2.355928e-02      1.275828423\n#&gt; 198982          1.111111e-04      0.008431373\n#&gt; 586854          1.469413e-03      0.092747990\n#&gt; 505491          7.868906e-04      0.073390584\n#&gt; 470261          1.509972e-04      0.035099339\n#&gt; 364934          1.847465e-03      0.142812367\n#&gt; 82225           1.904762e-04      0.043136264\n#&gt; 629896          1.864068e-03      0.286869695\n#&gt; 80338           3.682347e-03      0.278073303\n#&gt; 811000          5.941402e-04      0.114639984\n#&gt; 52076           8.899946e-03      0.577160279\n#&gt; 377048          4.138117e-03      0.296083656\n#&gt; 1031748         0.000000e+00      0.000000000\n#&gt; 785967          1.529101e-04      0.056328361\n#&gt; 813698          2.046611e-03      0.099081749\n#&gt; 43733           8.266718e-03      0.555595153\n#&gt; 53039          -8.695652e-05      0.006989474\n#&gt; 754600          0.000000e+00      0.012238095\n#&gt; 361943          6.166667e-04      0.045928953\n#&gt; 44563           2.781015e-03      0.152290924\n#&gt; 713922          5.662868e-03      0.421610182\n#&gt; 768246          2.651515e-04      0.039034151\n#&gt; 753104          7.692308e-05      0.024519692\n#&gt; 214572          3.878615e-03      0.236789843\n#&gt; 124605          1.557453e-03      0.063860534\n#&gt; 755506          8.333333e-05      0.018277433\n#&gt; 208718          9.265010e-04      0.049046791\n#&gt; 51448           3.736264e-04      0.027322807\n#&gt; 773215          4.924176e-04      0.070765302\n#&gt; 774502          5.057700e-03      0.302295594\n#&gt; 714453          2.951436e-03      0.269136920\n#&gt; 814260          2.109004e-02      1.167914813\n#&gt; 71672           3.453416e-04      0.033707246\n#&gt; 841641          4.397188e-03      0.283123287\n#&gt; 740554          5.755245e-04      0.026649966\n#&gt; 295985          1.720295e-02      1.030636887\n#&gt; 234376          7.142857e-05      0.003500000\n#&gt; 138672         -1.070234e-04      0.046126290\n#&gt; 139957          1.441026e-04      0.082820878\n#&gt; 308231          3.242318e-03      0.298078119\n#&gt; 309864          2.128852e-04      0.020000000\n#&gt; 341588          1.280000e-03      0.048557399\n#&gt; 308497          2.722592e-03      0.255757043\n#&gt; 269354          2.876623e-04      0.076426316\n#&gt; 376802         -8.333333e-05      0.026596859\n#&gt; 811028          8.695652e-05      0.018200000\n#&gt; 810133          3.333333e-04      0.003840000\n#&gt; 810448         -1.721612e-04      0.011636364\n#&gt; 364510         -7.692308e-05      0.010993700\n#&gt; 745343          1.451538e-03      0.095354563\n#&gt; 431296          0.000000e+00      0.009825259\n#&gt; 145112          1.269565e-04      0.032771429\n#&gt; 878280          1.934379e-03      0.200979555\n#&gt; 505881          1.388917e-03      0.115764666\n#&gt; 289645          1.587617e-03      0.095493112\n#&gt; 395708          8.275758e-04      0.060945700\n#&gt; 756401          2.414656e-03      0.277097612\n#&gt; 450152          7.671429e-04      0.056400559\n#&gt; 815794          0.000000e+00      0.000000000\n#&gt; 825740         -8.909091e-05      0.039441474\n#&gt; 823886          1.528272e-03      0.134314307\n#&gt; 207082          2.500000e-04      0.021511451\n#&gt; 376516          1.067989e-03      0.117471277\n#&gt; 813707          0.000000e+00      0.017846154\n#&gt; 213136          7.692308e-05      0.024806753\n#&gt; 823901          8.695652e-05      0.019218182\n#&gt; 234237          5.382855e-04      0.044756657\n#&gt; 549146          2.509972e-04      0.036506942\n#&gt; 306901          0.000000e+00      0.003733333\n#&gt; 810057          3.647155e-03      0.465736252\n#&gt; 841340          2.807882e-04      0.036046483\n#&gt; 81518           4.443230e-03      0.361790115\n#&gt; 813266          6.180087e-04      0.086607374\n#&gt; 785933          8.000000e-05      0.013836190\n#&gt; 416959          1.133977e-03      0.101134632\n#&gt; 52079          -1.105263e-04      0.021730866\n#&gt; 841620          3.458770e-03      0.254741355\n#&gt; 726236          9.848485e-05      0.021271368\n#&gt; 949934          3.781816e-04      0.083386869\n#&gt; 760299          4.169565e-04      0.044627273\n#&gt; 486110          1.370259e-03      0.210579541\n#&gt; 1474174         1.035347e-03      0.057149875\n#&gt; 878652          2.745765e-03      0.220575487\n#&gt; 85171           1.362983e-03      0.076186583\n#&gt; 753418          1.699133e-03      0.125231846\n#&gt; 626502          1.652295e-03      0.118498306\n#&gt; 814526          5.973740e-04      0.163620950\n#&gt; 299630          1.565550e-04      0.024879585\n#&gt; 502333          1.100554e-03      0.109891152\n#&gt; 435551         -1.785714e-04      0.031428571\n#&gt; 470128          0.000000e+00      0.000000000\n#&gt; 866694          4.713959e-04      0.036772105\n#&gt; 32299           8.288625e-04      0.110075346\n#&gt; 504791          2.100802e-03      0.224693805\n#&gt; 784257          1.535209e-03      0.136246524\n#&gt; 755228          1.104762e-04      0.021629630\n#&gt; 292996          2.704762e-04      0.010428571\n#&gt; 770014          4.761905e-04      0.042730037\n#&gt; 842918          1.671621e-03      0.164147188\n#&gt; 626555         -9.523810e-05      0.021112782\n#&gt; 877664          1.418668e-03      0.123829340\n#&gt; 843098          1.742424e-04      0.016969697\n#&gt; 811956          7.575758e-06      0.034239061\n#&gt; 244307         -7.692308e-05      0.007670034\n#&gt; 140806          1.600000e-04      0.024060606\n#&gt; 753215          2.651515e-04      0.088656469\n#&gt; 220096          2.693188e-04      0.077747386\n#&gt; 789376          1.100863e-03      0.158244828\n#&gt; 79520           9.366539e-04      0.054946700\n#&gt; 361974          7.927774e-04      0.077190460\n#&gt; 789357          3.956643e-04      0.070833767\n#&gt; 824704          1.694281e-03      0.136058304\n#&gt; 843287          0.000000e+00      0.000000000\n#&gt; 85259           2.704762e-04      0.013098039\n#&gt; 701751          4.171429e-04      0.028084488\n#&gt; 280837          1.651514e-03      0.161531200\n#&gt; 108351          9.730343e-04      0.086569103\n#&gt; 134495          0.000000e+00      0.005000000\n#&gt; 135058          3.538462e-04      0.024440729\n#&gt; 205490          3.557312e-04      0.017927273\n#&gt; 292522         -7.867495e-05      0.024051582\n#&gt; 193182          8.808696e-04      0.021786096\n#&gt; 244637          1.991587e-03      0.214855755\n#&gt; 130892          0.000000e+00      0.020522811\n#&gt; 240208          2.623847e-04      0.036044933\n#&gt; 135688          1.916258e-03      0.160438771\n#&gt; 110503          1.752381e-04      0.015418182\n#&gt; 413633          3.528139e-04      0.026709841\n#&gt; 783697          2.105263e-04      0.020035877\n#&gt; 247582          1.778656e-04      0.016098039\n#&gt; 323917          6.000000e-05      0.013042857\n#&gt; 782503          1.266807e-03      0.129148313",
    "crumbs": [
      "预测模型",
      "有监督模型（Supervised Models）",
      "基于树的方法"
    ]
  },
  {
    "objectID": "tree.html#装袋法",
    "href": "tree.html#装袋法",
    "title": "",
    "section": "\n1.3 装袋法",
    "text": "1.3 装袋法\nbagging 或 bootstrap aggregation",
    "crumbs": [
      "预测模型",
      "有监督模型（Supervised Models）",
      "基于树的方法"
    ]
  },
  {
    "objectID": "tree.html#梯度提升树",
    "href": "tree.html#梯度提升树",
    "title": "",
    "section": "\n1.4 梯度提升树",
    "text": "1.4 梯度提升树",
    "crumbs": [
      "预测模型",
      "有监督模型（Supervised Models）",
      "基于树的方法"
    ]
  },
  {
    "objectID": "UMAP.html",
    "href": "UMAP.html",
    "title": "",
    "section": "",
    "text": "Unsupervised ModelsUMAP CodeShow All CodeHide All CodeView Source\n1 UMAP\nUniform Manifold Approximation and Projection (UMAP)\nhttps://github.com/jlmelville/uwot\nhttps://github.com/tkonopka/umap\n2018年McInnes提出了算法，UMAP（Uniform Manifold Approximation and Projection for Dimension Reduction，一致的流形逼近和投影以进行降维）。 一致的流形近似和投影（UMAP）是一种降维技术，类似于t-SNE，可用于可视化，但也可用于一般的非线性降维。 该算法基于关于数据的三个假设：\n\n数据均匀分布在黎曼流形上（Riemannian manifold）；\n黎曼度量是局部恒定的（或可以这样近似）；\n流形是局部连接的。\n\nhttps://jlmelville.github.io/uwot/index.html\n\nCodelibrary(uwot)\nhead(iris)\n#&gt;   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n#&gt; 1          5.1         3.5          1.4         0.2  setosa\n#&gt; 2          4.9         3.0          1.4         0.2  setosa\n#&gt; 3          4.7         3.2          1.3         0.2  setosa\n#&gt; 4          4.6         3.1          1.5         0.2  setosa\n#&gt; 5          5.0         3.6          1.4         0.2  setosa\n#&gt; 6          5.4         3.9          1.7         0.4  setosa\ncolors = rainbow(length(unique(iris$Species)))\nnames(colors) = unique(iris$Species)\n# umap2 is a version of the umap() function with better defaults\niris_umap2 &lt;- umap2(iris[1:4]) |&gt; as_tibble()\n#&gt; Warning: The `x` argument of `as_tibble.matrix()` must have unique column names if\n#&gt; `.name_repair` is omitted as of tibble 2.0.0.\n#&gt; ℹ Using compatibility `.name_repair`.\n\nggplot(iris_umap2,aes(V1,V2))+\n    geom_text(aes(label=iris$Species),color=colors[iris$Species])\n\n\n\n\n\n\n\n\nCode# but you can still use the umap function (which most of the existing \n# documentation does)\niris_umap &lt;- umap(iris[1:4]) |&gt; as_tibble()\n\nggplot(iris_umap,aes(V1,V2))+\n    geom_text(aes(label=iris$Species),color=colors[iris$Species])\n\n\n\n\n\n\n\n\nCodelibrary(uwot)\n\nset.seed(42) # 为了结果可重复\nuwot_result &lt;- umap(iris[1:4])\n\n# 将结果转换为数据框\nuwot_df &lt;- as.data.frame(uwot_result)\ncolnames(uwot_df) &lt;- c(\"UMAP1\", \"UMAP2\")\nuwot_df$Species &lt;- iris$Species\n\n# 可视化\nggplot(uwot_df, aes(x = UMAP1, y = UMAP2, color = Species)) +\n  geom_point(size = 2) +\n  labs(title = \"UMAP of Iris Dataset (uwot)\",\n       x = \"UMAP Dimension 1\",\n       y = \"UMAP Dimension 2\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "预测模型",
      "Unsupervised Models",
      "UMAP"
    ]
  },
  {
    "objectID": "PCA.html",
    "href": "PCA.html",
    "title": "",
    "section": "",
    "text": "Unsupervised Models主成分分析 CodeShow All CodeHide All CodeView Source",
    "crumbs": [
      "预测模型",
      "Unsupervised Models",
      "主成分分析"
    ]
  },
  {
    "objectID": "PCA.html#自定义-pca-步骤",
    "href": "PCA.html#自定义-pca-步骤",
    "title": "",
    "section": "\n1.1 自定义 PCA 步骤",
    "text": "1.1 自定义 PCA 步骤\n\n1.1.1 数据标准化\nR中数据框 n个观测，p个变量\n\\[\nX=\n\\begin{bmatrix}\n  x_{11}& x_{12} & ... & x_{1p}\\\\\nx_{21} & x_{22} & ... & x_{2p}\\\\\n\\vdots  &  \\vdots &   & \\vdots \\\\\n  x_{n1}& x_{n2} & ... & x_{np}\n\\end{bmatrix}\n=(X_1,X_2,...X_p)\n\\]\n对原始数据矩阵标准化，消除量纲和数量级的影响。\n数据标准化确保变量在相同的尺度上，这对于PCA非常重要。\n使用R语言内置的 USArrests 数据集：\n\nCodedf &lt;- as_tibble(USArrests, rownames = \"state\") |&gt; column_to_rownames(\"state\")\nhead(df)\n#&gt;            Murder Assault UrbanPop Rape\n#&gt; Alabama      13.2     236       58 21.2\n#&gt; Alaska       10.0     263       48 44.5\n#&gt; Arizona       8.1     294       80 31.0\n#&gt; Arkansas      8.8     190       50 19.5\n#&gt; California    9.0     276       91 40.6\n#&gt; Colorado      7.9     204       78 38.7\n\ndf_center &lt;- scale(df,center = T,scale = T)\n\n\n\n1.1.2 计算协方差矩阵\n当\\(\\Sigma\\) 未知时，其用其估计值样本协方差矩阵Sp×p 代替\n\\[\nS=\\frac{AA^T}{n-1}\n\\]\n\n\n\\(A_{ p×n}\\) 显示来自每个变量值与其均值的偏差 \\(X_i-\\bar X\\)；\n\n\\((AA^T)_{ii}\\) 显示偏差平方和 （样本方差 \\(s_i^2\\) ）；\n\n\\((AA^T)_{ij}，i\\ne j\\) 显示样本协方差 \\(s_{ij} = (A 的行 i) · (A 的行 j)\\)。\n\n\nCode# 手动计算协方差矩阵\nA &lt;- as.matrix(t((df_center)))\nAA_T &lt;- A %*% t(A)\nS &lt;- AA_T / (nrow(df_center) - 1)\nS\n#&gt;              Murder   Assault   UrbanPop      Rape\n#&gt; Murder   1.00000000 0.8018733 0.06957262 0.5635788\n#&gt; Assault  0.80187331 1.0000000 0.25887170 0.6652412\n#&gt; UrbanPop 0.06957262 0.2588717 1.00000000 0.4113412\n#&gt; Rape     0.56357883 0.6652412 0.41134124 1.0000000\n# 内置协方差矩阵函数\ncov(df_center)\n#&gt;              Murder   Assault   UrbanPop      Rape\n#&gt; Murder   1.00000000 0.8018733 0.06957262 0.5635788\n#&gt; Assault  0.80187331 1.0000000 0.25887170 0.6652412\n#&gt; UrbanPop 0.06957262 0.2588717 1.00000000 0.4113412\n#&gt; Rape     0.56357883 0.6652412 0.41134124 1.0000000\n\n\n\n1.1.3 计算相关系数矩阵\n相关系数矩阵 \\(R=(r_{ij})\\) 的公式为：\n\\[\nr_{ij}=\\frac {S_{ij}}{\\sqrt{S_{ii}×S_{jj}}}\n\\]\n\nCode# 定义自定义函数计算相关系数矩阵\nr &lt;- function(df){\n    df &lt;- as.data.frame(df)\n    n=length(df)\n    names &lt;- colnames(df)\n    df &lt;- scale(df)\n    S &lt;- cov(df)\n    r &lt;- matrix(data = NA,n,n,dimnames = list(names,names))\n    for(i in 1:n){\n        for(j in 1:n){\n            r[i,j]=S[i,j]/sqrt(S[i,i]*S[j,j])\n        }\n    }\n    return(r)\n}\nr(df)\n#&gt;              Murder   Assault   UrbanPop      Rape\n#&gt; Murder   1.00000000 0.8018733 0.06957262 0.5635788\n#&gt; Assault  0.80187331 1.0000000 0.25887170 0.6652412\n#&gt; UrbanPop 0.06957262 0.2588717 1.00000000 0.4113412\n#&gt; Rape     0.56357883 0.6652412 0.41134124 1.0000000\n\n# 使用内置的相关系数矩阵函数\ncor(df_center)\n#&gt;              Murder   Assault   UrbanPop      Rape\n#&gt; Murder   1.00000000 0.8018733 0.06957262 0.5635788\n#&gt; Assault  0.80187331 1.0000000 0.25887170 0.6652412\n#&gt; UrbanPop 0.06957262 0.2588717 1.00000000 0.4113412\n#&gt; Rape     0.56357883 0.6652412 0.41134124 1.0000000\n\n\n\n1.1.4 总方差\n总方差T=所有特征值的总和=样本方差的总和=协方差矩阵的迹(对角线的总和)\nsum(eigen(AA_T)$values)=sum(diag(AA_T))= sum(svd$d^2)\n\nCode# AA^T的特征值\ny &lt;- eigen(AA_T)\ny$values\n#&gt; [1] 121.531837  48.498492  17.471596   8.498074\ny$vectors\n#&gt;            [,1]       [,2]       [,3]        [,4]\n#&gt; [1,] -0.5358995  0.4181809 -0.3412327  0.64922780\n#&gt; [2,] -0.5831836  0.1879856 -0.2681484 -0.74340748\n#&gt; [3,] -0.2781909 -0.8728062 -0.3780158  0.13387773\n#&gt; [4,] -0.5434321 -0.1673186  0.8177779  0.08902432\n\n# 特征值的和\nsum(y$values)\n#&gt; [1] 196\n\n# 迹\nsum(diag(AA_T))\n#&gt; [1] 196\n\n\n\n1.1.5 奇异值分解与主成分推导\nSVD公式：\n\\[\nA_{p×n}=U\\Sigma V^T\n\\]\nA 是中心化后的数据矩阵， U 是左奇异矩阵， \\(\\Sigma\\) 是奇异值对角矩阵， V 是右奇异矩阵（（也是主成分方向））\n主成分推导：\n\\[ PC=A\\cdot V=U \\Sigma  \\]\n在这个公式中：\n\n\\(U\\) 是包含左奇异向量的矩阵，表示样本在新坐标系中的坐标。\n\\(\\Sigma\\) 是包含奇异值的对角矩阵，这些奇异值与特征值相关，表示每个主成分的方差大小。\n\n\nCode\n# 进行奇异值分解\n\nsvd &lt;- svd(df_center)\nsvd$d\n#&gt; [1] 11.024148  6.964086  4.179904  2.915146\nsvd$u\n#&gt;               [,1]        [,2]         [,3]          [,4]\n#&gt;  [1,] -0.088502119 -0.16111249  0.105218608  0.0530665011\n#&gt;  [2,] -0.175119011 -0.15255799 -0.483145153 -0.1489378244\n#&gt;  [3,] -0.158329049  0.10603826 -0.012974042 -0.2834384049\n#&gt;  [4,]  0.012699298 -0.15917987 -0.027135114 -0.0620804497\n#&gt;  [5,] -0.226649068  0.21932910 -0.141759482 -0.1161380178\n#&gt;  [6,] -0.136005136  0.14038162 -0.259336498  0.0004974586\n#&gt;  [7,]  0.122004202  0.15479183  0.152346210 -0.0402308322\n#&gt;  [8,] -0.004284214  0.04624999  0.170197773 -0.2995093258\n#&gt;  [9,] -0.270566006 -0.00557636  0.136613685 -0.0326971796\n#&gt; [10,] -0.147204794 -0.18180252  0.081106695  0.3656676469\n#&gt; [11,]  0.081955040  0.22324195 -0.012026954  0.3065826885\n#&gt; [12,]  0.147251202 -0.02998994 -0.061530174 -0.1694899353\n#&gt; [13,] -0.123823808  0.09692418  0.160455000 -0.0414370084\n#&gt; [14,]  0.045389560  0.02154472 -0.054011475  0.1442115222\n#&gt; [15,]  0.202373535  0.01479136 -0.038974667  0.0059617844\n#&gt; [16,]  0.071558552  0.03840409 -0.006051930  0.0701237800\n#&gt; [17,]  0.067425851 -0.13624293  0.006718884  0.2277132300\n#&gt; [18,] -0.140517959 -0.12382100  0.185555941  0.1544203417\n#&gt; [19,]  0.215231159 -0.05350432  0.015555919 -0.1122203023\n#&gt; [20,] -0.158347534 -0.06079147  0.037242408 -0.1898534932\n#&gt; [21,]  0.043656895  0.20960067  0.144350623 -0.0609897144\n#&gt; [22,] -0.189334383  0.02208976 -0.091150533  0.0347643443\n#&gt; [23,]  0.151999911  0.08987636 -0.036252509  0.0228600295\n#&gt; [24,] -0.089483486 -0.34027971  0.175449706  0.0731840095\n#&gt; [25,] -0.062570302  0.03743606 -0.089392087  0.0766873549\n#&gt; [26,]  0.106451539 -0.07631705 -0.058472149  0.0420214180\n#&gt; [27,]  0.113651981  0.02757065 -0.041582129  0.0053970395\n#&gt; [28,] -0.258115678  0.11025209 -0.275529769  0.1068057898\n#&gt; [29,]  0.214071497  0.00257041 -0.008728664 -0.0112530536\n#&gt; [30,] -0.016304324  0.20604821  0.181049718  0.0826499280\n#&gt; [31,] -0.177802722 -0.02030605 -0.043504824 -0.1153016522\n#&gt; [32,] -0.151092550  0.11701618  0.152302994 -0.0045791345\n#&gt; [33,] -0.100877464 -0.31671218  0.204524432 -0.3240968906\n#&gt; [34,]  0.268696706 -0.08516514 -0.071353148 -0.0862511360\n#&gt; [35,]  0.020291306  0.10550966  0.007374849  0.1609363198\n#&gt; [36,]  0.027997563  0.04091867  0.003625902  0.0035087357\n#&gt; [37,] -0.005309061  0.07696200 -0.222585787 -0.0807475502\n#&gt; [38,]  0.079778211  0.08118230  0.094883089  0.1219329726\n#&gt; [39,]  0.077565243  0.21208574  0.324451737 -0.2083610270\n#&gt; [40,] -0.118598723 -0.27483477  0.071178009 -0.0446445538\n#&gt; [41,]  0.178498756 -0.11703880 -0.092198470 -0.0372092940\n#&gt; [42,] -0.089775081 -0.12228530 -0.044544714  0.2217051038\n#&gt; [43,] -0.121689077  0.05863443  0.116539361  0.2184216921\n#&gt; [44,]  0.049439812  0.20917537 -0.069565218 -0.0279528910\n#&gt; [45,]  0.251561949 -0.19933619 -0.199240942 -0.0492029259\n#&gt; [46,]  0.008650709 -0.02839251 -0.002773945  0.0717790646\n#&gt; [47,]  0.019477550  0.13790380 -0.147991604 -0.0749973365\n#&gt; [48,]  0.189347337 -0.20254292 -0.024814359  0.0447947015\n#&gt; [49,]  0.186754750  0.08689225  0.032888157  0.0625194853\n#&gt; [50,]  0.056521430 -0.04563221  0.056996643 -0.0565930091\nsvd$v\n#&gt;            [,1]       [,2]       [,3]        [,4]\n#&gt; [1,] -0.5358995 -0.4181809  0.3412327  0.64922780\n#&gt; [2,] -0.5831836 -0.1879856  0.2681484 -0.74340748\n#&gt; [3,] -0.2781909  0.8728062  0.3780158  0.13387773\n#&gt; [4,] -0.5434321  0.1673186 -0.8177779  0.08902432\n# 奇异值的平方和\nsum(svd$d^2)\n#&gt; [1] 196\n\n# 奇异值的对角矩阵\nD &lt;- diag(svd$d)\n\n#  df_center  X = U D V'\nX &lt;- svd$u %*% D %*% t(svd$v) \n\n#  D = U' X V\nt(svd$u) %*% X %*% svd$v\n#&gt;               [,1]         [,2]          [,3]          [,4]\n#&gt; [1,]  1.102415e+01 1.110223e-15  8.881784e-16  3.219647e-15\n#&gt; [2,]  2.220446e-16 6.964086e+00  6.661338e-16  1.318390e-15\n#&gt; [3,] -2.220446e-16 4.440892e-16  4.179904e+00 -8.881784e-16\n#&gt; [4,] -4.440892e-16 1.436351e-15 -9.436896e-16  2.915146e+00\n\n\n\n1.1.6 结果解释\n\n1.1.6.1 主成分荷载系数\n\nCode# 主成分荷载系数\nsvd$v\n#&gt;            [,1]       [,2]       [,3]        [,4]\n#&gt; [1,] -0.5358995 -0.4181809  0.3412327  0.64922780\n#&gt; [2,] -0.5831836 -0.1879856  0.2681484 -0.74340748\n#&gt; [3,] -0.2781909  0.8728062  0.3780158  0.13387773\n#&gt; [4,] -0.5434321  0.1673186 -0.8177779  0.08902432\n\n\n在PCA中，右奇异向量矩阵𝑉 的列向量代表数据在新的正交基上的方向，这些基是按数据中方差最大化的方向排列的。每个向量就是一个主成分方向。具体来说，矩阵 svd$v 中的每一列都是一个主成分， 且这些列向量可以看作是原始变量在新主成分空间中的线性组合系数。\n因此，svd$v 中的元素表示的是每个原始变量在对应主成分上的贡献，即主成分荷载系数（loadings）。\n例如，如果 V 的第j 个列向量为 \\([v_{1j},v_{2j},...,v_{pj}]\\) ，这意味着第j 个主成分可以表示为原始变量的线性组合：\n\\[\nPC_j=v_{1j}\\cdot x_1+v_{2j}\\cdot x_2+...+v_{pj}\\cdot x_p\n\\]\n其中， \\(x_1,x_2,...,x_p\\) 是原始变量， \\(v_{1j},v_{2j},...,v_{pj}\\) 是它们在第j 个主成分上的荷载系数。\n\n1.1.6.2 主成分得分\n主成分得分 (principal component scores) 代表了原始数据在新主成分轴上的坐标。\n具体来说，主成分得分可以表示为：\n\\[\nScores = U\\Sigma\n\\]\n\nCode# 得分\nsvd$u %*% D\n#&gt;              [,1]        [,2]        [,3]         [,4]\n#&gt;  [1,] -0.97566045 -1.12200121  0.43980366  0.154696581\n#&gt;  [2,] -1.93053788 -1.06242692 -2.01950027 -0.434175454\n#&gt;  [3,] -1.74544285  0.73845954 -0.05423025 -0.826264240\n#&gt;  [4,]  0.13999894 -1.10854226 -0.11342217 -0.180973554\n#&gt;  [5,] -2.49861285  1.52742672 -0.59254100 -0.338559240\n#&gt;  [6,] -1.49934074  0.97762966 -1.08400162  0.001450164\n#&gt;  [7,]  1.34499236  1.07798362  0.63679250 -0.117278736\n#&gt;  [8,] -0.04722981  0.32208890  0.71141032 -0.873113315\n#&gt;  [9,] -2.98275967 -0.03883425  0.57103206 -0.095317042\n#&gt; [10,] -1.62280742 -1.26608838  0.33901818  1.065974459\n#&gt; [11,]  0.90348448  1.55467609 -0.05027151  0.893733198\n#&gt; [12,]  1.62331903 -0.20885253 -0.25719021 -0.494087852\n#&gt; [13,] -1.36505197  0.67498834  0.67068647 -0.120794916\n#&gt; [14,]  0.50038122  0.15003926 -0.22576277  0.420397595\n#&gt; [15,]  2.23099579  0.10300828 -0.16291036  0.017379470\n#&gt; [16,]  0.78887206  0.26744941 -0.02529648  0.204421034\n#&gt; [17,]  0.74331256 -0.94880748  0.02808429  0.663817237\n#&gt; [18,] -1.54909076 -0.86230011  0.77560598  0.450157791\n#&gt; [19,]  2.37274014 -0.37260865  0.06502225 -0.327138529\n#&gt; [20,] -1.74564663 -0.42335704  0.15566968 -0.553450589\n#&gt; [21,]  0.48128007  1.45967706  0.60337172 -0.177793902\n#&gt; [22,] -2.08725025  0.15383500 -0.38100046  0.101343128\n#&gt; [23,]  1.67566951  0.62590670 -0.15153200  0.066640316\n#&gt; [24,] -0.98647919 -2.36973712  0.73336290  0.213342049\n#&gt; [25,] -0.68978426  0.26070794 -0.37365033  0.223554811\n#&gt; [26,]  1.17353751 -0.53147851 -0.24440796  0.122498555\n#&gt; [27,]  1.25291625  0.19200440 -0.17380930  0.015733156\n#&gt; [28,] -2.84550542  0.76780502 -1.15168793  0.311354436\n#&gt; [29,]  2.35995585  0.01790055 -0.03648498 -0.032804291\n#&gt; [30,] -0.17974128  1.43493745  0.75677041  0.240936580\n#&gt; [31,] -1.96012351 -0.14141308 -0.18184598 -0.336121113\n#&gt; [32,] -1.66566662  0.81491072  0.63661186 -0.013348844\n#&gt; [33,] -1.11208808 -2.20561081  0.85489245 -0.944789648\n#&gt; [34,]  2.96215223 -0.59309738 -0.29824930 -0.251434626\n#&gt; [35,]  0.22369436  0.73477837  0.03082616  0.469152817\n#&gt; [36,]  0.30864928  0.28496113  0.01515592  0.010228476\n#&gt; [37,] -0.05852787  0.53596999 -0.93038718 -0.235390872\n#&gt; [38,]  0.87948680  0.56536050  0.39660218  0.355452378\n#&gt; [39,]  0.85509072  1.47698328  1.35617705 -0.607402746\n#&gt; [40,] -1.30744986 -1.91397297  0.29751723 -0.130145378\n#&gt; [41,]  1.96779669 -0.81506822 -0.38538073 -0.108470512\n#&gt; [42,] -0.98969377 -0.85160534 -0.18619262  0.646302674\n#&gt; [43,] -1.34151838  0.40833518  0.48712332  0.636731051\n#&gt; [44,]  0.54503180  1.45671524 -0.29077592 -0.081486749\n#&gt; [45,]  2.77325613 -1.38819435 -0.83280797 -0.143433697\n#&gt; [46,]  0.09536670 -0.19772785 -0.01159482  0.209246429\n#&gt; [47,]  0.21472339  0.96037394 -0.61859067 -0.218628161\n#&gt; [48,]  2.08739306 -1.41052627 -0.10372163  0.130583080\n#&gt; [49,]  2.05881199  0.60512507  0.13746933  0.182253407\n#&gt; [50,]  0.62310061 -0.31778662  0.23824049 -0.164976866\n\n\n\n1.1.6.3 主成分标准差\n\n\\[\nStandard \\ Deviation \\ of \\ PC_i =\\frac{\\sigma_i}{\\sqrt{n-1}}\n\\]\n其中，n 是样本量，σ 是奇异值。\n\nCodesvd$d /sqrt(nrow(df_center)-1)\n#&gt; [1] 1.5748783 0.9948694 0.5971291 0.4164494\n\n\n\n1.1.6.4 方差贡献百分比\n在主成分分析 (PCA) 中，方差贡献百分比（variance explained ratio）是用来衡量每个主成分解释了数据总方差的比例。这个比例可以通过奇异值分解 (SVD) 的奇异值来计算。\n具体来说，方差贡献百分比的计算过程如下：\n\n计算每个主成分的方差。奇异值的平方 \\(\\sigma_i^2\\) 表示主成分 \\(𝑖\\)的方差。\n计算总方差，即所有奇异值的平方和。\n每个主成分的方差贡献百分比可以通过将每个奇异值的平方除以总方差来计算。\n\n\nCode# 方差贡献百分比\npct &lt;- svd$d^2/sum(svd$d^2)\npct\n#&gt; [1] 0.62006039 0.24744129 0.08914080 0.04335752\n\n# 累计方差贡献百分比\ncumsum(pct)\n#&gt; [1] 0.6200604 0.8675017 0.9566425 1.0000000",
    "crumbs": [
      "预测模型",
      "Unsupervised Models",
      "主成分分析"
    ]
  },
  {
    "objectID": "PCA.html#内置pca",
    "href": "PCA.html#内置pca",
    "title": "",
    "section": "\n1.2 内置PCA",
    "text": "1.2 内置PCA\n\nCodepca &lt;- prcomp(df_center)\npca\n#&gt; Standard deviations (1, .., p=4):\n#&gt; [1] 1.5748783 0.9948694 0.5971291 0.4164494\n#&gt; \n#&gt; Rotation (n x k) = (4 x 4):\n#&gt;                 PC1        PC2        PC3         PC4\n#&gt; Murder   -0.5358995 -0.4181809  0.3412327  0.64922780\n#&gt; Assault  -0.5831836 -0.1879856  0.2681484 -0.74340748\n#&gt; UrbanPop -0.2781909  0.8728062  0.3780158  0.13387773\n#&gt; Rape     -0.5434321  0.1673186 -0.8177779  0.08902432\nsummary(pca)\n#&gt; Importance of components:\n#&gt;                           PC1    PC2     PC3     PC4\n#&gt; Standard deviation     1.5749 0.9949 0.59713 0.41645\n#&gt; Proportion of Variance 0.6201 0.2474 0.08914 0.04336\n#&gt; Cumulative Proportion  0.6201 0.8675 0.95664 1.00000",
    "crumbs": [
      "预测模型",
      "Unsupervised Models",
      "主成分分析"
    ]
  },
  {
    "objectID": "PCA.html#可视化分析",
    "href": "PCA.html#可视化分析",
    "title": "",
    "section": "\n1.3 可视化分析",
    "text": "1.3 可视化分析\n\n1.3.1 判断主成分的个数\n\nCattell碎石图 图形变化最大处，即拐角处\nKaiser-Harris准则 特征值大于1，直线y=1以上\n平行分析 基于真实数据的特征值大于一组随机数据矩阵相应的特征值（虚线）\n\n1.3.2 碎石图\n\nCode# Create Scree Plot\nscreeplot(pca, type = \"lines\", main = \"Scree Plot\")\n\n\n\n\n\n\nCode\nlibrary(ggplot2)\nexplained_variance &lt;- pca$sdev^2 / sum(pca$sdev^2)\nexplained_variance_df &lt;- data.frame(\n  Principal_Component = paste0(\"PC\", 1:length(explained_variance)),\n  Explained_Variance = explained_variance\n)\n\nggplot(explained_variance_df, aes(x = Principal_Component, y = Explained_Variance)) +\n  geom_bar(stat = \"identity\", fill = \"skyblue\") +\n  geom_line(aes(group = 1), color = \"blue\") +\n  geom_point(color = \"red\") +\n  labs(title = \"Scree Plot\", x = \"Principal Component\", y = \"Explained Variance\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n1.3.2.1 平行分析\n\nCodefa_parallel &lt;- psych::fa.parallel(df_center, fa = \"pc\", n.iter = 100)\n\n\n\n\n\n\n#&gt; Parallel analysis suggests that the number of factors =  NA  and the number of components =  1\n\n\nCodesvd$v\n#&gt;            [,1]       [,2]       [,3]        [,4]\n#&gt; [1,] -0.5358995 -0.4181809  0.3412327  0.64922780\n#&gt; [2,] -0.5831836 -0.1879856  0.2681484 -0.74340748\n#&gt; [3,] -0.2781909  0.8728062  0.3780158  0.13387773\n#&gt; [4,] -0.5434321  0.1673186 -0.8177779  0.08902432\ntibble(x = 1:4, pc1 = svd$v[, 1]) %&gt;%\n    ggplot(aes(x, pc1)) +\n    geom_point() +\n    theme_classic() +\n    theme(panel.border = element_rect(\n        color = \"black\",\n        fill = NA,\n    ), # 添加四周框线\n    )\n\n\n\n\n\n\nCode\nplot(svd$v[,1],ylab = \"1st PC\")\n\n\n\n\n\n\nCodeplot(svd$v[,1],svd$v[,2],xlab=\"lst PC\",ylab=\"2nd PC\")",
    "crumbs": [
      "预测模型",
      "Unsupervised Models",
      "主成分分析"
    ]
  },
  {
    "objectID": "PCA.html#主成分分析-1",
    "href": "PCA.html#主成分分析-1",
    "title": "",
    "section": "\n1.4 主成分分析",
    "text": "1.4 主成分分析\n\nCodelibrary(tidymodels)\n\n\n\nCodedf &lt;- as_tibble(USArrests, rownames = \"state\")\ndf\n#&gt; # A tibble: 50 × 5\n#&gt;    state       Murder Assault UrbanPop  Rape\n#&gt;    &lt;chr&gt;        &lt;dbl&gt;   &lt;int&gt;    &lt;int&gt; &lt;dbl&gt;\n#&gt;  1 Alabama       13.2     236       58  21.2\n#&gt;  2 Alaska        10       263       48  44.5\n#&gt;  3 Arizona        8.1     294       80  31  \n#&gt;  4 Arkansas       8.8     190       50  19.5\n#&gt;  5 California     9       276       91  40.6\n#&gt;  6 Colorado       7.9     204       78  38.7\n#&gt;  7 Connecticut    3.3     110       77  11.1\n#&gt;  8 Delaware       5.9     238       72  15.8\n#&gt;  9 Florida       15.4     335       80  31.9\n#&gt; 10 Georgia       17.4     211       60  25.8\n#&gt; # ℹ 40 more rows\n\ndf |&gt;\n  select(-state) |&gt;\n  map_dfr(mean)  #apply(.,2,mean)\n#&gt; # A tibble: 1 × 4\n#&gt;   Murder Assault UrbanPop  Rape\n#&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1   7.79    171.     65.5  21.2\n\n\n\nCodedf_pca &lt;- df |&gt;\n  select(-state) |&gt;\n  stats::prcomp(scale = TRUE)\n\n\n主成分得分，表示主成分与原有观测的相关系数\n\nCodedf_pca$x\n#&gt;               PC1         PC2         PC3          PC4\n#&gt;  [1,] -0.97566045 -1.12200121  0.43980366  0.154696581\n#&gt;  [2,] -1.93053788 -1.06242692 -2.01950027 -0.434175454\n#&gt;  [3,] -1.74544285  0.73845954 -0.05423025 -0.826264240\n#&gt;  [4,]  0.13999894 -1.10854226 -0.11342217 -0.180973554\n#&gt;  [5,] -2.49861285  1.52742672 -0.59254100 -0.338559240\n#&gt;  [6,] -1.49934074  0.97762966 -1.08400162  0.001450164\n#&gt;  [7,]  1.34499236  1.07798362  0.63679250 -0.117278736\n#&gt;  [8,] -0.04722981  0.32208890  0.71141032 -0.873113315\n#&gt;  [9,] -2.98275967 -0.03883425  0.57103206 -0.095317042\n#&gt; [10,] -1.62280742 -1.26608838  0.33901818  1.065974459\n#&gt; [11,]  0.90348448  1.55467609 -0.05027151  0.893733198\n#&gt; [12,]  1.62331903 -0.20885253 -0.25719021 -0.494087852\n#&gt; [13,] -1.36505197  0.67498834  0.67068647 -0.120794916\n#&gt; [14,]  0.50038122  0.15003926 -0.22576277  0.420397595\n#&gt; [15,]  2.23099579  0.10300828 -0.16291036  0.017379470\n#&gt; [16,]  0.78887206  0.26744941 -0.02529648  0.204421034\n#&gt; [17,]  0.74331256 -0.94880748  0.02808429  0.663817237\n#&gt; [18,] -1.54909076 -0.86230011  0.77560598  0.450157791\n#&gt; [19,]  2.37274014 -0.37260865  0.06502225 -0.327138529\n#&gt; [20,] -1.74564663 -0.42335704  0.15566968 -0.553450589\n#&gt; [21,]  0.48128007  1.45967706  0.60337172 -0.177793902\n#&gt; [22,] -2.08725025  0.15383500 -0.38100046  0.101343128\n#&gt; [23,]  1.67566951  0.62590670 -0.15153200  0.066640316\n#&gt; [24,] -0.98647919 -2.36973712  0.73336290  0.213342049\n#&gt; [25,] -0.68978426  0.26070794 -0.37365033  0.223554811\n#&gt; [26,]  1.17353751 -0.53147851 -0.24440796  0.122498555\n#&gt; [27,]  1.25291625  0.19200440 -0.17380930  0.015733156\n#&gt; [28,] -2.84550542  0.76780502 -1.15168793  0.311354436\n#&gt; [29,]  2.35995585  0.01790055 -0.03648498 -0.032804291\n#&gt; [30,] -0.17974128  1.43493745  0.75677041  0.240936580\n#&gt; [31,] -1.96012351 -0.14141308 -0.18184598 -0.336121113\n#&gt; [32,] -1.66566662  0.81491072  0.63661186 -0.013348844\n#&gt; [33,] -1.11208808 -2.20561081  0.85489245 -0.944789648\n#&gt; [34,]  2.96215223 -0.59309738 -0.29824930 -0.251434626\n#&gt; [35,]  0.22369436  0.73477837  0.03082616  0.469152817\n#&gt; [36,]  0.30864928  0.28496113  0.01515592  0.010228476\n#&gt; [37,] -0.05852787  0.53596999 -0.93038718 -0.235390872\n#&gt; [38,]  0.87948680  0.56536050  0.39660218  0.355452378\n#&gt; [39,]  0.85509072  1.47698328  1.35617705 -0.607402746\n#&gt; [40,] -1.30744986 -1.91397297  0.29751723 -0.130145378\n#&gt; [41,]  1.96779669 -0.81506822 -0.38538073 -0.108470512\n#&gt; [42,] -0.98969377 -0.85160534 -0.18619262  0.646302674\n#&gt; [43,] -1.34151838  0.40833518  0.48712332  0.636731051\n#&gt; [44,]  0.54503180  1.45671524 -0.29077592 -0.081486749\n#&gt; [45,]  2.77325613 -1.38819435 -0.83280797 -0.143433697\n#&gt; [46,]  0.09536670 -0.19772785 -0.01159482  0.209246429\n#&gt; [47,]  0.21472339  0.96037394 -0.61859067 -0.218628161\n#&gt; [48,]  2.08739306 -1.41052627 -0.10372163  0.130583080\n#&gt; [49,]  2.05881199  0.60512507  0.13746933  0.182253407\n#&gt; [50,]  0.62310061 -0.31778662  0.23824049 -0.164976866\n\n# by default    df_pca$x\nbroom::tidy(df_pca, matrix = \"scores\") |&gt; \n    pivot_wider(id_cols = everything(),\n                names_from = PC,\n                names_prefix = \"PC\",\n               values_from = value)\n#&gt; # A tibble: 50 × 5\n#&gt;      row     PC1     PC2     PC3      PC4\n#&gt;    &lt;int&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n#&gt;  1     1 -0.976  -1.12    0.440   0.155  \n#&gt;  2     2 -1.93   -1.06   -2.02   -0.434  \n#&gt;  3     3 -1.75    0.738  -0.0542 -0.826  \n#&gt;  4     4  0.140  -1.11   -0.113  -0.181  \n#&gt;  5     5 -2.50    1.53   -0.593  -0.339  \n#&gt;  6     6 -1.50    0.978  -1.08    0.00145\n#&gt;  7     7  1.34    1.08    0.637  -0.117  \n#&gt;  8     8 -0.0472  0.322   0.711  -0.873  \n#&gt;  9     9 -2.98   -0.0388  0.571  -0.0953 \n#&gt; 10    10 -1.62   -1.27    0.339   1.07   \n#&gt; # ℹ 40 more rows\n\n\n主成分荷载（loading）：表示主成分与原有变量的相关系数\n\nCodedf_pca$rotation\n#&gt;                 PC1        PC2        PC3         PC4\n#&gt; Murder   -0.5358995 -0.4181809  0.3412327  0.64922780\n#&gt; Assault  -0.5831836 -0.1879856  0.2681484 -0.74340748\n#&gt; UrbanPop -0.2781909  0.8728062  0.3780158  0.13387773\n#&gt; Rape     -0.5434321  0.1673186 -0.8177779  0.08902432\n\n# df_pca$Rotation\ntidy(df_pca, matrix = \"loadings\") |&gt; \n    pivot_wider(\n        names_from = PC,\n        names_prefix = \"PC\",\n        values_from = value,\n    )\n#&gt; # A tibble: 4 × 5\n#&gt;   column      PC1    PC2    PC3     PC4\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 Murder   -0.536 -0.418  0.341  0.649 \n#&gt; 2 Assault  -0.583 -0.188  0.268 -0.743 \n#&gt; 3 UrbanPop -0.278  0.873  0.378  0.134 \n#&gt; 4 Rape     -0.543  0.167 -0.818  0.0890\n\n\n例如：\n\\[\nPC_1=-0.536Murrder-0.583Assault-0.278UrbanPop-0.543Rape\n\\]\n\nCode\ntidy(df_pca, matrix = \"loadings\") |&gt;\n  ggplot(aes(value, column)) +\n  facet_wrap(~ PC) +\n  geom_col() +\n  scale_x_continuous(labels = scales::percent)\n\n\n\n\n\n\n\n特征值 eigenvalues，高维椭球的主轴长度，相关矩阵的特征值。\n方差百分比贡献。\n\nCode# screen plot\ntidy(df_pca, matrix = \"eigenvalues\") |&gt;\n    ggplot(aes(PC, percent)) +\n    geom_point(color = \"red\") +\n    geom_line()+\n    scale_y_continuous(labels = scales::percent)\n\n\n\n\n\n\n\n\n1.4.1 判断主成分的个数psych::fa.parallel(mat)\n\n\nCattell碎石图 图形变化最大处，即拐角处\nKaiser-Harris准则 特征值大于1，直线y=1以上\n平行分析 基于真实数据的特征值大于一组随机数据矩阵相应的特征值（虚线）\n\n\nCode# 平行分析\nfa_parallel &lt;- psych::fa.parallel(df_center, fa = \"pc\", n.iter = 100)\n\n\n\n\n\n\n#&gt; Parallel analysis suggests that the number of factors =  NA  and the number of components =  1",
    "crumbs": [
      "预测模型",
      "Unsupervised Models",
      "主成分分析"
    ]
  },
  {
    "objectID": "PCA.html#tidy-主成分分析",
    "href": "PCA.html#tidy-主成分分析",
    "title": "",
    "section": "\n1.4 tidy 主成分分析",
    "text": "1.4 tidy 主成分分析\n\nCodelibrary(tidymodels)\n\n\n\nCodedf &lt;- as_tibble(USArrests, rownames = \"state\")\ndf\n#&gt; # A tibble: 50 × 5\n#&gt;    state       Murder Assault UrbanPop  Rape\n#&gt;    &lt;chr&gt;        &lt;dbl&gt;   &lt;int&gt;    &lt;int&gt; &lt;dbl&gt;\n#&gt;  1 Alabama       13.2     236       58  21.2\n#&gt;  2 Alaska        10       263       48  44.5\n#&gt;  3 Arizona        8.1     294       80  31  \n#&gt;  4 Arkansas       8.8     190       50  19.5\n#&gt;  5 California     9       276       91  40.6\n#&gt;  6 Colorado       7.9     204       78  38.7\n#&gt;  7 Connecticut    3.3     110       77  11.1\n#&gt;  8 Delaware       5.9     238       72  15.8\n#&gt;  9 Florida       15.4     335       80  31.9\n#&gt; 10 Georgia       17.4     211       60  25.8\n#&gt; # ℹ 40 more rows\n\ndf |&gt;\n  select(-state) |&gt;\n  map_dfr(mean)  #apply(.,2,mean)\n#&gt; # A tibble: 1 × 4\n#&gt;   Murder Assault UrbanPop  Rape\n#&gt;    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1   7.79    171.     65.5  21.2\n\n\n\nCodedf_pca &lt;- df |&gt;\n  select(-state) |&gt;\n  stats::prcomp(scale = TRUE)\n\n\n主成分得分，表示主成分与原有观测的相关系数\n\nCodedf_pca$x\n#&gt;               PC1         PC2         PC3          PC4\n#&gt;  [1,] -0.97566045 -1.12200121  0.43980366  0.154696581\n#&gt;  [2,] -1.93053788 -1.06242692 -2.01950027 -0.434175454\n#&gt;  [3,] -1.74544285  0.73845954 -0.05423025 -0.826264240\n#&gt;  [4,]  0.13999894 -1.10854226 -0.11342217 -0.180973554\n#&gt;  [5,] -2.49861285  1.52742672 -0.59254100 -0.338559240\n#&gt;  [6,] -1.49934074  0.97762966 -1.08400162  0.001450164\n#&gt;  [7,]  1.34499236  1.07798362  0.63679250 -0.117278736\n#&gt;  [8,] -0.04722981  0.32208890  0.71141032 -0.873113315\n#&gt;  [9,] -2.98275967 -0.03883425  0.57103206 -0.095317042\n#&gt; [10,] -1.62280742 -1.26608838  0.33901818  1.065974459\n#&gt; [11,]  0.90348448  1.55467609 -0.05027151  0.893733198\n#&gt; [12,]  1.62331903 -0.20885253 -0.25719021 -0.494087852\n#&gt; [13,] -1.36505197  0.67498834  0.67068647 -0.120794916\n#&gt; [14,]  0.50038122  0.15003926 -0.22576277  0.420397595\n#&gt; [15,]  2.23099579  0.10300828 -0.16291036  0.017379470\n#&gt; [16,]  0.78887206  0.26744941 -0.02529648  0.204421034\n#&gt; [17,]  0.74331256 -0.94880748  0.02808429  0.663817237\n#&gt; [18,] -1.54909076 -0.86230011  0.77560598  0.450157791\n#&gt; [19,]  2.37274014 -0.37260865  0.06502225 -0.327138529\n#&gt; [20,] -1.74564663 -0.42335704  0.15566968 -0.553450589\n#&gt; [21,]  0.48128007  1.45967706  0.60337172 -0.177793902\n#&gt; [22,] -2.08725025  0.15383500 -0.38100046  0.101343128\n#&gt; [23,]  1.67566951  0.62590670 -0.15153200  0.066640316\n#&gt; [24,] -0.98647919 -2.36973712  0.73336290  0.213342049\n#&gt; [25,] -0.68978426  0.26070794 -0.37365033  0.223554811\n#&gt; [26,]  1.17353751 -0.53147851 -0.24440796  0.122498555\n#&gt; [27,]  1.25291625  0.19200440 -0.17380930  0.015733156\n#&gt; [28,] -2.84550542  0.76780502 -1.15168793  0.311354436\n#&gt; [29,]  2.35995585  0.01790055 -0.03648498 -0.032804291\n#&gt; [30,] -0.17974128  1.43493745  0.75677041  0.240936580\n#&gt; [31,] -1.96012351 -0.14141308 -0.18184598 -0.336121113\n#&gt; [32,] -1.66566662  0.81491072  0.63661186 -0.013348844\n#&gt; [33,] -1.11208808 -2.20561081  0.85489245 -0.944789648\n#&gt; [34,]  2.96215223 -0.59309738 -0.29824930 -0.251434626\n#&gt; [35,]  0.22369436  0.73477837  0.03082616  0.469152817\n#&gt; [36,]  0.30864928  0.28496113  0.01515592  0.010228476\n#&gt; [37,] -0.05852787  0.53596999 -0.93038718 -0.235390872\n#&gt; [38,]  0.87948680  0.56536050  0.39660218  0.355452378\n#&gt; [39,]  0.85509072  1.47698328  1.35617705 -0.607402746\n#&gt; [40,] -1.30744986 -1.91397297  0.29751723 -0.130145378\n#&gt; [41,]  1.96779669 -0.81506822 -0.38538073 -0.108470512\n#&gt; [42,] -0.98969377 -0.85160534 -0.18619262  0.646302674\n#&gt; [43,] -1.34151838  0.40833518  0.48712332  0.636731051\n#&gt; [44,]  0.54503180  1.45671524 -0.29077592 -0.081486749\n#&gt; [45,]  2.77325613 -1.38819435 -0.83280797 -0.143433697\n#&gt; [46,]  0.09536670 -0.19772785 -0.01159482  0.209246429\n#&gt; [47,]  0.21472339  0.96037394 -0.61859067 -0.218628161\n#&gt; [48,]  2.08739306 -1.41052627 -0.10372163  0.130583080\n#&gt; [49,]  2.05881199  0.60512507  0.13746933  0.182253407\n#&gt; [50,]  0.62310061 -0.31778662  0.23824049 -0.164976866\n\n# by default    df_pca$x\nbroom::tidy(df_pca, matrix = \"scores\") |&gt; \n    pivot_wider(id_cols = everything(),\n                names_from = PC,\n                names_prefix = \"PC\",\n               values_from = value)\n#&gt; # A tibble: 50 × 5\n#&gt;      row     PC1     PC2     PC3      PC4\n#&gt;    &lt;int&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n#&gt;  1     1 -0.976  -1.12    0.440   0.155  \n#&gt;  2     2 -1.93   -1.06   -2.02   -0.434  \n#&gt;  3     3 -1.75    0.738  -0.0542 -0.826  \n#&gt;  4     4  0.140  -1.11   -0.113  -0.181  \n#&gt;  5     5 -2.50    1.53   -0.593  -0.339  \n#&gt;  6     6 -1.50    0.978  -1.08    0.00145\n#&gt;  7     7  1.34    1.08    0.637  -0.117  \n#&gt;  8     8 -0.0472  0.322   0.711  -0.873  \n#&gt;  9     9 -2.98   -0.0388  0.571  -0.0953 \n#&gt; 10    10 -1.62   -1.27    0.339   1.07   \n#&gt; # ℹ 40 more rows\n\n\n主成分荷载（loading）：表示主成分与原有变量的相关系数\n\nCodedf_pca$rotation\n#&gt;                 PC1        PC2        PC3         PC4\n#&gt; Murder   -0.5358995 -0.4181809  0.3412327  0.64922780\n#&gt; Assault  -0.5831836 -0.1879856  0.2681484 -0.74340748\n#&gt; UrbanPop -0.2781909  0.8728062  0.3780158  0.13387773\n#&gt; Rape     -0.5434321  0.1673186 -0.8177779  0.08902432\n\n# df_pca$Rotation\ntidy(df_pca, matrix = \"loadings\") |&gt; \n    pivot_wider(\n        names_from = PC,\n        names_prefix = \"PC\",\n        values_from = value,\n    )\n#&gt; # A tibble: 4 × 5\n#&gt;   column      PC1    PC2    PC3     PC4\n#&gt;   &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n#&gt; 1 Murder   -0.536 -0.418  0.341  0.649 \n#&gt; 2 Assault  -0.583 -0.188  0.268 -0.743 \n#&gt; 3 UrbanPop -0.278  0.873  0.378  0.134 \n#&gt; 4 Rape     -0.543  0.167 -0.818  0.0890\n\n\n例如：\n\\[\nPC_1=-0.536Murrder-0.583Assault-0.278UrbanPop-0.543Rape\n\\]\n\nCode\ntidy(df_pca, matrix = \"loadings\") |&gt;\n  ggplot(aes(value, column)) +\n  facet_wrap(~ PC) +\n  geom_col() +\n  scale_x_continuous(labels = scales::percent)\n\n\n\n\n\n\n\n特征值 eigenvalues，高维椭球的主轴长度，相关矩阵的特征值。\n方差百分比贡献。\n\nCode# screen plot\ntidy(df_pca, matrix = \"eigenvalues\") |&gt;\n    ggplot(aes(PC, percent)) +\n    geom_point(color = \"red\") +\n    geom_line()+\n    scale_y_continuous(labels = scales::percent)",
    "crumbs": [
      "预测模型",
      "Unsupervised Models",
      "主成分分析"
    ]
  }
]