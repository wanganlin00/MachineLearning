# 分类

## LDA

Fisher线性判别分析（Linear Discriminant Analysis, LDA）

Fisher判别法试图最大化类间差异（不同类别的数据点彼此远离）并最小化类内差异（同一类别的数据点尽可能聚集。

它侧重于最大化类间差异（between-class variance）与类内差异（within-class variance）的比率

### MASS

```{r}
# 加载MASS包，它包含了lda函数
library(MASS)

# 加载内置的鸢尾花数据集
data(iris)

# 查看数据集结构
str(iris)

# 应用Fisher线性判别分析
# 使用鸢尾花数据集的前四列作为特征，Species作为类别
lda_model <- lda(Species ~ ., data=iris)

# 查看判别模型的摘要
summary(lda_model)
lda_model
# 打印判别函数的系数
print(lda_model$coefficients)

# 使用判别模型对数据进行分类
predicted_species <- predict(lda_model, iris)

# 计算准确率
accuracy <- sum(predicted_species$class == iris$Species) / nrow(iris)
print(paste("分类准确率:", accuracy))

# 可视化判别结果
plot(lda_model)
```

1.  **模型调用（Call）**:

    -   显示了创建LDA模型时使用的函数调用。在这个例子中，模型使用鸢尾花数据集的所有特征（Sepal.Length, Sepal.Width, Petal.Length, Petal.Width）来预测物种（Species）。

2.  **组的先验概率（Prior probabilities of groups）**:

    -   显示了每个物种（setosa, versicolor, virginica）的先验概率。这里每个物种的先验概率都是0.3333，意味着在没有任何额外信息的情况下，每个物种出现的概率是相同的。

3.  **组内均值（Group means）**:

    -   显示了每个物种在各个特征上的均值。例如，setosa物种的花萼长度（Sepal.Length）均值是5.006，花萼宽度（Sepal.Width）均值是3.428，花瓣长度（Petal.Length）均值是1.462，花瓣宽度（Petal.Width）均值是0.246。

4.  **线性判别系数（Coefficients of linear discriminants）**:

    -   显示了两个线性判别函数（LD1和LD2）的系数。这些系数用于计算判别分数，以区分不同的物种。例如，LD1判别函数中，花萼长度（Sepal.Length）的系数是0.8293776，花萼宽度（Sepal.Width）的系数是1.5344731，以此类推。

5.  **特征值的比例（Proportion of trace）**:

    -   显示了每个线性判别函数对总方差的解释比例。在这个例子中，LD1解释了99.12%的方差，而LD2仅解释了0.88%的方差。这表明LD1是主要的判别方向，而LD2的贡献相对较小。

如何使用这些信息：

-   可以使用这些系数来计算每个观测值在LD1和LD2上的判别分数。判别分数的计算公式为： LD1=0.8293776×Sepal.Length+1.5344731×Sepal.Width−2.2012117×Petal.Length−2.8104603×Petal.WidthLD1=0.8293776×Sepal.Length+1.5344731×Sepal.Width−2.2012117×Petal.Length−2.8104603×Petal.Width LD2=−0.02410215×Sepal.Length−2.16452123×Sepal.Width+0.93192121×Petal.Length−2.83918785×Petal.WidthLD2=−0.02410215×Sepal.Length−2.16452123×Sepal.Width+0.93192121×Petal.Length−2.83918785×Petal.Width

-   通常，主要的判别函数（在这个例子中是LD1）足以进行有效的分类。如果需要，也可以使用LD2作为辅助。

-   根据判别分数，可以确定每个观测值最有可能属于的物种类别。

### tidymodels

```{r}
library(tidymodels)
library(discrim)
```

```{r}
Smarket <- read_csv("data/Smarket.csv")
Smarket$Direction <- factor(Smarket$Direction)
head(Smarket)
```

```{r}
lda_spec <- discrim_linear() %>%
  set_mode("classification") %>%
  set_engine("MASS")
lda_fit <- lda_spec %>%
  fit(Direction ~ Lag1 + Lag2, data = Smarket)

lda_fit
```

```{r}
predict(lda_fit, new_data = Smarket)
predict(lda_fit, new_data = Smarket, type = "prob")
augment(lda_fit, new_data = Smarket) %>%
  conf_mat(truth = Direction, estimate = .pred_class) 

augment(lda_fit, new_data = Smarket) %>%
  accuracy(truth = Direction, estimate = .pred_class) 
```

## K-Nearest Neighbors

```{r}
df3 <- read_csv("data/Smarket.csv") 
head(df3)
df3$Direction <- factor(df3$Direction)
```

```{r}
knn_spec <- nearest_neighbor(neighbors = 3) |> 
  set_mode("classification") |> 
  set_engine("kknn")

knn_fit <- knn_spec |>
  fit(Direction ~ Lag1 + Lag2, data = df3)

knn_fit

```

```{r}
augment(knn_fit, new_data = df3) |> 
  conf_mat(truth = Direction, estimate = .pred_class) 
```

```{r}
augment(knn_fit, new_data = df3) |>
  accuracy(truth = Direction, estimate = .pred_class) 
```

## 模型比较

```{r}
models <- list("LDA" = lda_fit,
               "KNN" = knn_fit)
preds <- imap_dfr(models, augment, 
                  new_data = Smarket, .id = "model")

preds %>%
  dplyr::select(model, Direction, .pred_class, .pred_Down, .pred_Up)
```

### 灵敏度和特异性

```{r}
multi_metric <- metric_set( sensitivity, specificity)  # accuracy


preds %>%
  group_by(model) %>%
  multi_metric(truth = Direction, estimate = .pred_class)
```

### ROC 曲线

```{r}
preds %>%
  group_by(model) %>%
  roc_curve(Direction, .pred_Down) %>%
  autoplot()
```
