# 主成分分析

主成分分析(Principal component analysis，PCA) 是一种线性降维方法。

<https://bryanhanson.github.io/LearnPCA/articles//Vig_04_Scores_Loadings.html>

对于一组变量$X_1,X_2,...,X_p$,存在它们的线性组合 **Y**，令$Var(y_1)$最大，得到$y_1$，再找$y_2$，$y_2$与$y_1$正交，以此类推，找到一组无关主成分 **Y**。

$$
y_i=a_{i1}x_1+a_{i2}x_2+...+a_{ip}x_p\\
Cov(y_i,y_j)=
\begin{cases}  &\lambda_i,\ i=j \\  
& 0,\ i\ne j
\end{cases}
$$

## 自定义 PCA 步骤

### 数据标准化

R中数据框 n个观测，p个变量

$$
X=
\begin{bmatrix}
  x_{11}& x_{12} & ... & x_{1p}\\
 x_{21} & x_{22} & ... & x_{2p}\\
 \vdots  &  \vdots &   & \vdots \\
  x_{n1}& x_{n2} & ... & x_{np}
\end{bmatrix}
=(X_1,X_2,...X_p)
$$

对原始数据矩阵标准化，消除量纲和数量级的影响。

数据标准化确保变量在相同的尺度上，这对于PCA非常重要。

使用R语言内置的 `USArrests` 数据集：

```{r}
df <- as_tibble(USArrests, rownames = "state") |> column_to_rownames("state")
head(df)

df_center <- scale(df,center = T,scale = T)
```

### 计算协方差矩阵

当$\Sigma$ 未知时，其用其估计值样本协方差矩阵S~p×p~ 代替

$$
S=\frac{AA^T}{n-1}
$$

-   $A_{ p×n}$ 显示来自每个变量值与其均值的偏差 $X_i-\bar X$；
-   $(AA^T)_{ii}$ 显示偏差平方和 （样本方差 $s_i^2$ ）；
-   $(AA^T)_{ij}，i\ne j$ 显示样本协方差 $s_{ij} = (A 的行 i) · (A 的行 j)$。

```{r}
# 手动计算协方差矩阵
A <- as.matrix(t((df_center)))
AA_T <- A %*% t(A)
S <- AA_T / (nrow(df_center) - 1)
S
# 内置协方差矩阵函数
cov(df_center)
```

### 计算相关系数矩阵

相关系数矩阵 $R=(r_{ij})$ 的公式为：

$$
r_{ij}=\frac {S_{ij}}{\sqrt{S_{ii}×S_{jj}}}
$$

```{r}
# 定义自定义函数计算相关系数矩阵
r <- function(df){
    df <- as.data.frame(df)
    n=length(df)
    names <- colnames(df)
    df <- scale(df)
    S <- cov(df)
    r <- matrix(data = NA,n,n,dimnames = list(names,names))
    for(i in 1:n){
        for(j in 1:n){
            r[i,j]=S[i,j]/sqrt(S[i,i]*S[j,j])
        }
    }
    return(r)
}
r(df)

# 使用内置的相关系数矩阵函数
cor(df_center)
```

### 总方差

总方差T=所有特征值的总和=样本方差的总和=协方差矩阵的迹(对角线的总和)

`sum(eigen(AA_T)$values)`=`sum(diag(AA_T))`= `sum(svd$d^2)`

```{r}
# AA^T的特征值
y <- eigen(AA_T)
y$values
y$vectors

# 特征值的和
sum(y$values)

# 迹
sum(diag(AA_T))
```

### 奇异值分解与主成分推导

SVD公式：

$$
A_{p×n}=U\Sigma V^T 
$$

A 是中心化后的数据矩阵， U 是左奇异矩阵， $\Sigma$ 是奇异值对角矩阵， V 是右奇异矩阵（（也是主成分方向））

主成分推导：

$$ PC=A\cdot V=U \Sigma  $$

在这个公式中：

-   $U$ 是包含左奇异向量的矩阵，表示样本在新坐标系中的坐标。

-   $\Sigma$ 是包含奇异值的对角矩阵，这些奇异值与特征值相关，表示每个主成分的方差大小。

```{r}

# 进行奇异值分解

svd <- svd(df_center)
svd$d
svd$u
svd$v
# 奇异值的平方和
sum(svd$d^2)

# 奇异值的对角矩阵
D <- diag(svd$d)

#  df_center  X = U D V'
X <- svd$u %*% D %*% t(svd$v) 

#  D = U' X V
t(svd$u) %*% X %*% svd$v
```

### 结果解释

#### 主成分荷载系数

```{r}
# 主成分荷载系数
svd$v
```

在PCA中，右奇异向量矩阵𝑉 的列向量代表数据在新的正交基上的方向，这些基是按数据中方差最大化的方向排列的。每个向量就是一个主成分方向。具体来说，矩阵 `svd$v` 中的每一列都是一个**主成分**， 且这些列向量可以看作是原始变量在新主成分空间中的线性组合系数。

因此，`svd$v` 中的元素表示的是每个原始变量在对应主成分上的贡献，即主成分荷载系数（loadings）。

例如，如果 `V` 的第j 个列向量为 $[v_{1j},v_{2j},...,v_{pj}]$ ，这意味着第j 个主成分可以表示为原始变量的线性组合：

$$
PC_j=v_{1j}\cdot x_1+v_{2j}\cdot x_2+...+v_{pj}\cdot x_p
$$

其中， $x_1,x_2,...,x_p$ 是原始变量， $v_{1j},v_{2j},...,v_{pj}$ 是它们在第j 个主成分上的荷载系数。

#### 主成分得分

主成分得分 (principal component scores) 代表了原始数据在新主成分轴上的坐标。

具体来说，主成分得分可以表示为：

$$
Scores = U\Sigma
$$

```{r}
# 得分
svd$u %*% D
```

#### 主成分标准差

![](images/clipboard-305502058.png)

$$
Standard \ Deviation \ of \ PC_i =\frac{\sigma_i}{\sqrt{n-1}}
$$

其中，n 是样本量，σ 是奇异值。

```{r}
svd$d /sqrt(nrow(df_center)-1)
```

#### 方差贡献百分比

在主成分分析 (PCA) 中，方差贡献百分比（variance explained ratio）是用来衡量每个主成分解释了数据总方差的比例。这个比例可以通过奇异值分解 (SVD) 的奇异值来计算。

具体来说，方差贡献百分比的计算过程如下：

1.  计算每个主成分的方差。奇异值的平方 $\sigma_i^2$ 表示主成分 $𝑖$的方差。

2.  计算总方差，即所有奇异值的平方和。

3.  每个主成分的方差贡献百分比可以通过将每个奇异值的平方除以总方差来计算。

```{r}
# 方差贡献百分比
pct <- svd$d^2/sum(svd$d^2)
pct

# 累计方差贡献百分比
cumsum(pct)
```

## 内置PCA

```{r}
pca <- prcomp(df_center)
pca
summary(pca)
```

## 可视化分析

### 判断主成分的个数

1.  Cattell碎石图 图形变化最大处，即拐角处
2.  Kaiser-Harris准则 特征值大于1，直线y=1以上
3.  平行分析 基于真实数据的特征值大于一组随机数据矩阵相应的特征值（虚线）

### 碎石图

```{r}
# Create Scree Plot
screeplot(pca, type = "lines", main = "Scree Plot")

library(ggplot2)
explained_variance <- pca$sdev^2 / sum(pca$sdev^2)
explained_variance_df <- data.frame(
  Principal_Component = paste0("PC", 1:length(explained_variance)),
  Explained_Variance = explained_variance
)

ggplot(explained_variance_df, aes(x = Principal_Component, y = Explained_Variance)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  geom_line(aes(group = 1), color = "blue") +
  geom_point(color = "red") +
  labs(title = "Scree Plot", x = "Principal Component", y = "Explained Variance") +
  theme_minimal()
```

#### 平行分析

```{r}
fa_parallel <- psych::fa.parallel(df_center, fa = "pc", n.iter = 100)
```

```{r}
svd$v
tibble(x = 1:4, pc1 = svd$v[, 1]) %>%
    ggplot(aes(x, pc1)) +
    geom_point() +
    theme_classic() +
    theme(panel.border = element_rect(
        color = "black",
        fill = NA,
    ), # 添加四周框线
    )

plot(svd$v[,1],ylab = "1st PC")
plot(svd$v[,1],svd$v[,2],xlab="lst PC",ylab="2nd PC")

```

## tidy 主成分分析

```{r}
library(tidymodels)
```

```{r}
df <- as_tibble(USArrests, rownames = "state")
df

df |>
  select(-state) |>
  map_dfr(mean)  #apply(.,2,mean)
```

```{r}
df_pca <- df |>
  select(-state) |>
  stats::prcomp(scale = TRUE)
```

主成分得分，表示主成分与原有观测的相关系数

```{r}
df_pca$x

# by default    df_pca$x
broom::tidy(df_pca, matrix = "scores") |> 
    pivot_wider(id_cols = everything(),
                names_from = PC,
                names_prefix = "PC",
               values_from = value)
```

主成分荷载（loading）：表示主成分与原有变量的相关系数

```{r}
df_pca$rotation

# df_pca$Rotation
tidy(df_pca, matrix = "loadings") |> 
    pivot_wider(
        names_from = PC,
        names_prefix = "PC",
        values_from = value,
    )
```

例如：

$$
PC_1=-0.536Murrder-0.583Assault-0.278UrbanPop-0.543Rape
$$

```{r}

tidy(df_pca, matrix = "loadings") |>
  ggplot(aes(value, column)) +
  facet_wrap(~ PC) +
  geom_col() +
  scale_x_continuous(labels = scales::percent)
```

特征值 eigenvalues，高维椭球的主轴长度，相关矩阵的特征值。

方差百分比贡献。

```{r}
# screen plot
tidy(df_pca, matrix = "eigenvalues") |>
    ggplot(aes(PC, percent)) +
    geom_point(color = "red") +
    geom_line()+
    scale_y_continuous(labels = scales::percent)
```
